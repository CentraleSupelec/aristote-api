{
    "original_file_name": "RI1.mp4",
    "language": "fr",
    "sentences": [
        {
            "start": 0,
            "end": 12,
            "text": "Bonjour, nous entamons aujourd'hui la derni\u00e8re th\u00e9matique qui sera trait\u00e9e dans ce cours sp\u00e9cifique de la ST4 et qui traite de l'apprentissage pour la recherche d'informations."
        },
        {
            "start": 12,
            "end": 20,
            "text": "Ce sera un cours en deux parties, il y aura donc la suite de ce cours qui sera le sujet de la prochaine s\u00e9ance."
        },
        {
            "start": 20,
            "end": 35,
            "text": "Rapidement, pour introduire ce nouveau paradigme pour la recherche d'informations, je vais d'abord revenir sur les syst\u00e8mes de recherche d'informations classiques que nous avons vus jusqu'alors."
        },
        {
            "start": 35,
            "end": 53,
            "text": "Ce que nous avons vu jusqu'alors, c'est que pour une requ\u00eate de N\u00e9Q qui traduit un besoin d'information, une collection de documents qui est index\u00e9e, on a vu un certain nombre de mod\u00e8les de recherche qui permettent de retourner une liste ordonn\u00e9e de documents."
        },
        {
            "start": 53,
            "end": 59,
            "text": "Ces mod\u00e8les de recherche peuvent \u00eatre divers, nous en avons vu plusieurs lors de ce cours."
        },
        {
            "start": 59,
            "end": 87,
            "text": "Par exemple, ici, ce mod\u00e8le de recherche pourrait \u00eatre la probabilit\u00e9 de pertinence sachant Q et D et qui pourrait \u00eatre estim\u00e9e en utilisant par exemple le mod\u00e8le BM25 qui est fonction de l'IDF et puis d'une fonction de pond\u00e9ration portant sur la fr\u00e9quence des termes dans un document et puis une normalisation par la longueur du document."
        },
        {
            "start": 87,
            "end": 98,
            "text": "Tout au long du cours, on a vu plusieurs types de mod\u00e8les, des mod\u00e8les bas\u00e9s similarit\u00e9s comme le mod\u00e8le bool\u00e9en ou le mod\u00e8le vectoriel."
        },
        {
            "start": 98,
            "end": 107,
            "text": "On a aussi pr\u00e9sent\u00e9 plusieurs mod\u00e8les probabilistes, notamment le mod\u00e8le d'ind\u00e9pendance binaire et le mod\u00e8le BM25."
        },
        {
            "start": 107,
            "end": 125,
            "text": "Et puis, plus derni\u00e8rement, on a pr\u00e9sent\u00e9 des mod\u00e8les qui prennent en compte la structure de la collection et notamment tous les mod\u00e8les qui sont bas\u00e9s sur une analyse des liens de la collection, comme par exemple le mod\u00e8le du page rank ou le mod\u00e8le head."
        },
        {
            "start": 125,
            "end": 130,
            "text": "Quelques discussions sur ces mod\u00e8les de classement."
        },
        {
            "start": 130,
            "end": 137,
            "text": "Pour un mod\u00e8le particulier, on a vu que le param\u00e9trage est souvent difficile, surtout quand il y a beaucoup de param\u00e8tres."
        },
        {
            "start": 137,
            "end": 150,
            "text": "Typiquement, pour le mod\u00e8le vectoriel, quelle est la bonne mesure de pond\u00e9ration \u00e0 utiliser pour le document pour la requ\u00eate, quelle est la bonne distance \u00e0 utiliser, etc."
        },
        {
            "start": 150,
            "end": 153,
            "text": "Pour comparer deux mod\u00e8les, on a vu aussi que c'\u00e9tait compliqu\u00e9."
        },
        {
            "start": 153,
            "end": 157,
            "text": "\u00c7a, c'est notamment tout le cours qui a trait \u00e0 l'\u00e9valuation."
        },
        {
            "start": 157,
            "end": 168,
            "text": "La comparaison rigoureuse, c'est quelque chose qui est assez difficile et notamment en recherche d'informations, on met plut\u00f4t en \u0153uvre des \u00e9valuations par benchmark, donc une \u00e9valuation empirique."
        },
        {
            "start": 168,
            "end": 175,
            "text": "On peut souvent \u00eatre dans des probl\u00e9matiques o\u00f9 on est dans des cas de surparam\u00e9trage."
        },
        {
            "start": 175,
            "end": 186,
            "text": "Et puis, si cette fois-ci on prend une collection de mod\u00e8les, par exemple l'ensemble des mod\u00e8les probabilistes versus l'ensemble des mod\u00e8les par similarit\u00e9, \u00e7a se complexifie."
        },
        {
            "start": 186,
            "end": 189,
            "text": "On a notamment beaucoup de mod\u00e8les qui existent."
        },
        {
            "start": 189,
            "end": 194,
            "text": "Dans la litt\u00e9rature, on en d\u00e9nombre plus d'une centaine, voire maintenant m\u00eame des milliers."
        },
        {
            "start": 194,
            "end": 199,
            "text": "Et il y a plusieurs questions qui peuvent se poser, notamment quel est le meilleur des mod\u00e8les ?"
        },
        {
            "start": 199,
            "end": 204,
            "text": "Comment je peux comparer ces mod\u00e8les et \u00e9ventuellement comment je peux les combiner ?"
        },
        {
            "start": 204,
            "end": 215,
            "text": "Les syst\u00e8mes actuels, notamment les syst\u00e8mes de recherche web que vous utilisez quotidiennement, pour une requ\u00eate donn\u00e9e, ils calculent souvent plusieurs centaines de fonctions de score de base."
        },
        {
            "start": 215,
            "end": 220,
            "text": "Entre cette requ\u00eate et chaque document de la collection, et ils combinent ces scores."
        },
        {
            "start": 220,
            "end": 223,
            "text": "Donc une question cl\u00e9, c'est comment combiner ces scores ?"
        },
        {
            "start": 223,
            "end": 228,
            "text": "Et notamment, \u00e7a c'est toute la science qu'on appelle la science des CEO."
        },
        {
            "start": 228,
            "end": 243,
            "text": "Avec typiquement, vous pourrez trouver un ensemble d'articles assez g\u00e9n\u00e9ralistes qui justement parlent des 200 facteurs de classement de Google et qui donnent des recommandations, notamment si vous voulez que votre site web soit bien r\u00e9f\u00e9renc\u00e9."
        },
        {
            "start": 243,
            "end": 250,
            "text": "Il y a un paquet d'illustrations assez rigolotes d'ailleurs sur ces facteurs et param\u00e8tres."
        },
        {
            "start": 250,
            "end": 266,
            "text": "Alors voil\u00e0, notamment une illustration sous la forme d'une table p\u00e9riodique, justement des facteurs de succ\u00e8s des SEO, notamment pour tout ce qui est r\u00e9f\u00e9rencement de site web."
        },
        {
            "start": 266,
            "end": 272,
            "text": "Avec donc des facteurs qui sont propres \u00e0 la page, des facteurs qui sont ext\u00e9rieurs, contextuels, etc."
        },
        {
            "start": 272,
            "end": 277,
            "text": "Il y a toute une litt\u00e9rature sur ce sujet l\u00e0."
        },
        {
            "start": 277,
            "end": 302,
            "text": "Voil\u00e0, et c'est l\u00e0 qu'intervient l'apprentissage pour la recherche d'informations, parce qu'en fait les techniques d'apprentissage automatique, c'est des bons outils pour le param\u00e9trage automatique, pour combiner plusieurs \u00e9vidences, donc la question de la combinaison et de la fusion des scores dont on parlait juste avant, et puis ils permettent aussi d'\u00e9viter le surparam\u00e9trage."
        },
        {
            "start": 302,
            "end": 314,
            "text": "Donc toutes ces approches d'apprentissage pour la RI, elles ont un nom, c'est ce qu'on appelle le Learning to Rank, et \u00e7a rassemble l'ensemble des m\u00e9thodes qui vont utiliser des approches d'apprentissage pour le probl\u00e8me de l'ordonnancement."
        },
        {
            "start": 314,
            "end": 323,
            "text": "C'est la science qu'on appelle la science d'apprendre \u00e0 ordonner, et qui a explos\u00e9 dans le domaine de la recherche d'informations \u00e0 partir de 2005."
        },
        {
            "start": 323,
            "end": 331,
            "text": "Tous les moteurs de recherche actuels utilisent des approches \u00e0 base d'apprentissage, et m\u00eame aujourd'hui \u00e0 base d'apprentissage profond."
        },
        {
            "start": 331,
            "end": 341,
            "text": "Notamment, ce dont on va parler aujourd'hui, c'est l'optimisation automatique \u00e0 l'aide d'algorithmes d'apprentissage de la fonction d'ordonnancement."
        },
        {
            "start": 341,
            "end": 348,
            "text": "Et donc on va introduire un nouveau mod\u00e8le pour la recherche d'informations qui va suivre ce sch\u00e9ma-l\u00e0."
        },
        {
            "start": 348,
            "end": 365,
            "text": "C'est-\u00e0-dire qu'on va consid\u00e9rer un ensemble de donn\u00e9es, qui vont \u00eatre nos donn\u00e9es d'apprentissage, qui sont compos\u00e9es de requ\u00eates et d'un ensemble de documents qui sont associ\u00e9s \u00e0 ces requ\u00eates, et bien s\u00fbr de jugements de pertinence entre cette requ\u00eate et ces documents."
        },
        {
            "start": 365,
            "end": 370,
            "text": "Donc \u00e7a on va le faire, on va prendre en compte des donn\u00e9es pour plusieurs requ\u00eates."
        },
        {
            "start": 370,
            "end": 385,
            "text": "Et puis sur cet ensemble de donn\u00e9es, qu'on va appeler l'ensemble d'apprentissage, on va utiliser un syst\u00e8me d'apprentissage qui va apprendre une fonction de classement F de QD."
        },
        {
            "start": 385,
            "end": 413,
            "text": "Et puis pour une nouvelle requ\u00eate, Q de M plus 1, et notre ensemble de documents, notre collection qui reste index\u00e9e, avec l'ensemble des principes d'indexation qu'on a vus jusqu'alors, et bien on va appliquer ce mod\u00e8le appris, ce syst\u00e8me d'ordonnancement appris, pour classer les documents pertinents pour la requ\u00eate QI de M1, avec ce mod\u00e8le d'apprentissage."
        },
        {
            "start": 413,
            "end": 416,
            "text": "Donc on aura toujours en sortie une liste ordonn\u00e9e de documents."
        },
        {
            "start": 416,
            "end": 418,
            "text": "\u00c7a, \u00e7a ne change pas."
        },
        {
            "start": 418,
            "end": 433,
            "text": "Ce qui change, c'est vraiment ce syst\u00e8me d'apprentissage qui va utiliser des donn\u00e9es d'apprentissage pour apprendre cette fonction d'ordonnancement, qui elle ensuite est utilis\u00e9e de mani\u00e8re classique dans un syst\u00e8me d'ordonnancement."
        },
        {
            "start": 433,
            "end": 449,
            "text": "Donc l'apprentissage pour l'AERI, en fait, il va reposer sur deux concepts principaux, qui sont la notation des donn\u00e9es et la repr\u00e9sentation des couples requ\u00eates documents dans un espace de caract\u00e9ristiques qu'il faudra d\u00e9terminer."
        },
        {
            "start": 449,
            "end": 456,
            "text": "\u00c7a, c'est une \u00e9tape tr\u00e8s importante, qu'on appelle l'\u00e9tape de description ou feature engineering."
        },
        {
            "start": 456,
            "end": 478,
            "text": "Et puis, il y a la phase d'apprentissage en tant que telle, avec l'utilisation d'une structure d'apprentissage en deux \u00e9tapes assez classique, avec une \u00e9tape d'apprentissage de la fonction d'ordonnancement F de QD, et puis une \u00e9tape de test, d'utilisation du mod\u00e8le appris sur de nouvelles requ\u00eates."
        },
        {
            "start": 478,
            "end": 497,
            "text": "Voil\u00e0, donc au final, on a vraiment ce sch\u00e9ma-l\u00e0 pour la recherche d'informations avec apprentissage, donc pour le learning to rank, un ensemble de jeux de donn\u00e9es d'apprentissage qui sont compos\u00e9s de couples requ\u00eates documents qu'on va d\u00e9crire."
        },
        {
            "start": 497,
            "end": 507,
            "text": "Voil\u00e0, donc notamment, en fait, une grosse partie du travail, \u00e7a va \u00eatre de constituer ce vecteur X, qui est un vecteur caract\u00e9ristique de ce couple requ\u00eates documents."
        },
        {
            "start": 507,
            "end": 519,
            "text": "Ces donn\u00e9es, elles sont labellis\u00e9es, c'est-\u00e0-dire qu'on a une v\u00e9rit\u00e9 terrain, et cette v\u00e9rit\u00e9 terrain, en fait, elle est fonction de la pertinence du document D1 pour la requ\u00eate Q1."
        },
        {
            "start": 519,
            "end": 525,
            "text": "Et puis, donc, on a un syst\u00e8me d'apprentissage qui va reposer sur l'optimisation d'une fonction et d'un crit\u00e8re."
        },
        {
            "start": 525,
            "end": 532,
            "text": "On va donc, en sortie, avoir un mod\u00e8le F qui est appris \u00e0 partir de ces donn\u00e9es d'apprentissage."
        },
        {
            "start": 532,
            "end": 548,
            "text": "Et puis, donc, on a nos nouvelles donn\u00e9es qui sont nos donn\u00e9es de test ou nos donn\u00e9es de production o\u00f9, cette fois-ci, on n'a pas la v\u00e9rit\u00e9 terrain, donc on n'a pas les valeurs de pertinence, et l'objectif, \u00e7a va \u00eatre justement de pr\u00e9dire ces valeurs avec le mod\u00e8le appris."
        },
        {
            "start": 548,
            "end": 560,
            "text": "Donc, on va d\u00e9crire de la m\u00eame mani\u00e8re le couple Q1 D1, et puis, en fait, ce que va retourner le syst\u00e8me d'ordonnancement, c'est une liste ordonn\u00e9e des documents, donc selon cette fonction d'ordonnancement."
        },
        {
            "start": 560,
            "end": 572,
            "text": "On va donc d\u00e9tailler tous ces concepts lors de ce cours, et je vais d'abord vous rappeler quelques g\u00e9n\u00e9ralit\u00e9s sur l'apprentissage, et notamment l'apprentissage supervis\u00e9."
        },
        {
            "start": 572,
            "end": 579,
            "text": "Puis, on parlera du cas sp\u00e9cifique de la cat\u00e9gorisation de documents appliqu\u00e9s \u00e0 la recherche d'informations."
        },
        {
            "start": 579,
            "end": 583,
            "text": "On parlera donc de la recherche d'informations et de l'ordonnancement."
        },
        {
            "start": 583,
            "end": 601,
            "text": "Et puis, la semaine prochaine, on parlera plus sp\u00e9cifiquement, donc on continuera \u00e0 la partie arri\u00e8re d'ordonnancement, et on parlera aussi plus sp\u00e9cifiquement des donn\u00e9es d'apprentissage \u00e0 utiliser ou \u00e0 constituer, et des diff\u00e9rents jeux de tests qui sont \u00e0 disposition de la communaut\u00e9."
        },
        {
            "start": 601,
            "end": 606,
            "text": "Donc, pour commencer, quelques g\u00e9n\u00e9ralit\u00e9s sur l'apprentissage."
        },
        {
            "start": 606,
            "end": 623,
            "text": "On va consid\u00e9rer un processus d'inf\u00e9rence en trois \u00e9tapes, o\u00f9 la premi\u00e8re \u00e9tape va \u00eatre d'observer un ph\u00e9nom\u00e8ne, puis \u00e0 partir de cette observation du ph\u00e9nom\u00e8ne, \u00e0 partir de donn\u00e9es d'observation de ce ph\u00e9nom\u00e8ne, on va construire un mod\u00e8le associ\u00e9 \u00e0 ce ph\u00e9nom\u00e8ne."
        },
        {
            "start": 623,
            "end": 629,
            "text": "Et puis, l'id\u00e9e, c'est ensuite d'utiliser ce mod\u00e8le pour faire des pr\u00e9dictions relatives justement \u00e0 ce ph\u00e9nom\u00e8ne."
        },
        {
            "start": 629,
            "end": 634,
            "text": "L'apprentissage automatique, c'est l'automatisation de ce processus d'inf\u00e9rence."
        },
        {
            "start": 634,
            "end": 646,
            "text": "Avec une hypoth\u00e8se forte qui dit qu'il existe des relations entre les donn\u00e9es et que les algorithmes d'apprentissage vont nous permettre de les trouver."
        },
        {
            "start": 646,
            "end": 656,
            "text": "Il existe diff\u00e9rentes familles d'algorithmes d'apprentissage, et classiquement, on les cat\u00e9gorise selon deux grands axes."
        },
        {
            "start": 656,
            "end": 663,
            "text": "Le premier axe, c'est le mode d'apprentissage, avec diff\u00e9rents modes d'apprentissage assez connus."
        },
        {
            "start": 663,
            "end": 678,
            "text": "Notamment l'apprentissage supervis\u00e9, pour lequel on va vouloir apprendre des relations entre des entr\u00e9es et des sorties, avec un oracle qui nous donne des exemples qui vont exprimer ces relations."
        },
        {
            "start": 678,
            "end": 688,
            "text": "On va avoir \u00e0 disposition ce qu'on va appeler un ensemble d'apprentissage, avec des donn\u00e9es d'entr\u00e9e qui vont \u00eatre labellis\u00e9es."
        },
        {
            "start": 688,
            "end": 692,
            "text": "L'autre mode d'apprentissage, c'est l'apprentissage non supervis\u00e9."
        },
        {
            "start": 692,
            "end": 700,
            "text": "Cette fois-ci, on n'a pas d'oracle, donc on n'a pas d'exemple qui exprime des relations entre des entr\u00e9es et des sorties."
        },
        {
            "start": 700,
            "end": 705,
            "text": "Ce qu'on va chercher \u00e0 faire, c'est apprendre une structure dans un ensemble de donn\u00e9es."
        },
        {
            "start": 705,
            "end": 711,
            "text": "Typiquement, ces techniques d'apprentissage non supervis\u00e9, c'est toutes les techniques qu'on appelle les techniques de clustering."
        },
        {
            "start": 711,
            "end": 721,
            "text": "Et puis, on a d'autres paradigmes, comme par exemple l'apprentissage semi-supervis\u00e9, o\u00f9 l'objectif, c'est toujours bien d'apprendre les relations entre des entr\u00e9es et des sorties."
        },
        {
            "start": 721,
            "end": 730,
            "text": "Parmi les exemples \u00e0 notre disposition, l'oracle nous fournit la sortie seulement pour un petit nombre de ces exemples."
        },
        {
            "start": 730,
            "end": 744,
            "text": "L'id\u00e9e de l'apprentissage semi-supervis\u00e9, \u00e7a va \u00eatre de tirer parti de ces exemples, et l'id\u00e9e de l'apprentissage semi-supervis\u00e9, \u00e7a va \u00eatre de tirer parti des autres donn\u00e9es, c'est-\u00e0-dire des donn\u00e9es sans \u00e9tiquettes."
        },
        {
            "start": 744,
            "end": 764,
            "text": "C'est un mode d'apprentissage qui revient beaucoup au go\u00fbt du jour, notamment \u00e0 cause du succ\u00e8s des techniques d'apprentissage profond, qui n\u00e9cessitent lors de la phase d'apprentissage d'\u00e9norm\u00e9ment de donn\u00e9es supervis\u00e9es, donc de donn\u00e9es annot\u00e9es, qui sont co\u00fbteuses \u00e0 obtenir \u00e0 grande \u00e9chelle."
        },
        {
            "start": 764,
            "end": 775,
            "text": "Les donn\u00e9es sans annotation sont moins co\u00fbteuses \u00e0 obtenir, et l'id\u00e9e du semi-supervis\u00e9, c'est aussi de tirer parti de ces donn\u00e9es qui sont plus faciles \u00e0 obtenir."
        },
        {
            "start": 775,
            "end": 782,
            "text": "On peut aussi classer les techniques d'apprentissage selon le type de probl\u00e8me qu'on souhaite traiter."
        },
        {
            "start": 782,
            "end": 790,
            "text": "Typiquement, pour les algorithmes d'apprentissage supervis\u00e9, on a souvent deux grands types de probl\u00e8mes, le probl\u00e8me qu'on appelle la r\u00e9gression et la classification."
        },
        {
            "start": 790,
            "end": 794,
            "text": "Ce qui diff\u00e9rencie ces probl\u00e8mes, c'est le type des valeurs de sortie."
        },
        {
            "start": 794,
            "end": 807,
            "text": "Typiquement, pour la r\u00e9gression, on va chercher \u00e0 pr\u00e9dire une valeur continue, et pour la classification, on va chercher \u00e0 pr\u00e9dire une valeur dans un ensemble discret, dans un ensemble de classes discr\u00e8tes."
        },
        {
            "start": 807,
            "end": 832,
            "text": "On a aussi beaucoup d'autres approches, beaucoup d'autres familles d'apprentissage, notamment l'apprentissage par renforcement, qui est connu, parce que c'est notamment le type d'apprentissage qui a \u00e9t\u00e9 mis en oeuvre en partie dans AlphaGo, qui a vaincu l'Is\u00e9dol au jeu de Go, et qui consiste \u00e0 apprendre un comportement face \u00e0 diverses situations, en optimisant une r\u00e9compense quantitative."
        },
        {
            "start": 832,
            "end": 850,
            "text": "On a aussi l'apprentissage actif, o\u00f9 on va demander \u00e0 un utilisateur ou un p\u00f4le d'utilisateurs d'annoter un sous-ensemble de donn\u00e9es de mani\u00e8re incr\u00e9mentale."
        },
        {
            "start": 850,
            "end": 856,
            "text": "Et puis prendre en compte ce sous-ensemble de donn\u00e9es \u00e0 noter au fur et \u00e0 mesure pour am\u00e9liorer notre mod\u00e8le."
        },
        {
            "start": 856,
            "end": 864,
            "text": "Et puis il y a d'autres modes d'apprentissage, comme l'apprentissage par analogie, le m\u00e9ta-apprentissage, etc."
        },
        {
            "start": 864,
            "end": 869,
            "text": "Dans ce cours, on va principalement se r\u00e9f\u00e9rer \u00e0 l'apprentissage supervis\u00e9."
        },
        {
            "start": 869,
            "end": 874,
            "text": "Je vais d\u00e9j\u00e0 commencer par rappeler quelques principes de l'apprentissage supervis\u00e9."
        },
        {
            "start": 874,
            "end": 890,
            "text": "On va consid\u00e9rer un espace d'entr\u00e9e X qui est inclus dans Rd, et un espace de sortie Y qui est inclus dans R. On peut par exemple vouloir pr\u00e9dire une valeur dans R, ou on va pouvoir aussi vouloir pr\u00e9dire des cat\u00e9gories."
        },
        {
            "start": 890,
            "end": 896,
            "text": "La r\u00e9gression pr\u00e9dit une valeur dans R, ou cat\u00e9gorie, donc \u00e7a va \u00eatre des choses discr\u00e8tes."
        },
        {
            "start": 896,
            "end": 944,
            "text": "L'hypoth\u00e8se fondamentale de l'apprentissage supervis\u00e9, c'est cette hypoth\u00e8se-l\u00e0, qui dit que les paires d'exemples XY sont IID, c'est-\u00e0-dire qu'elles sont identiquement et ind\u00e9pendamment distribu\u00e9es suivant une distribution de probabilit\u00e9 fixe, mais qui est inconnue, D. Ce qu'on a \u00e0 disposition, c'est un ensemble d'\u00e9chantillons, c'est-\u00e0-dire une s\u00e9quence de n paires XY qui sont donc bien s\u00fbr g\u00e9n\u00e9r\u00e9es suivant cette distribution de probabilit\u00e9 fixe, mais inconnue, D. Cet ensemble de couples, de paires XY, c'est ce qu'on appelle l'ensemble d'apprentissage."
        },
        {
            "start": 944,
            "end": 959,
            "text": "Le but de l'apprentissage supervis\u00e9, \u00e7a va \u00eatre de construire une fonction F qui va de X dans Y et qui va pr\u00e9dire la sortie Y d'une nouvelle observation X avec une probabilit\u00e9 d'erreur minimale."
        },
        {
            "start": 959,
            "end": 996,
            "text": "La plupart des techniques d'apprentissage supervis\u00e9 reposent sur des travaux th\u00e9oriques, notamment qu'on doit \u00e0 Vladimir Vapnik et ses coll\u00e8gues, et qui a montr\u00e9 qu'on pouvait borner la probabilit\u00e9 d'erreur, donc cette probabilit\u00e9 d'erreur qu'on veut minimale, RF, qui est le risque fonctionnel, je reviendrai sur cette notion juste un peu plus tard, par l'erreur empirique de F, l'erreur qu'on va pouvoir mesurer sur l'ensemble d'apprentissage, plus deux termes qui sont fonction de la complexit\u00e9 de la classe de fonctions, donc la classe de fonctions F qu'on va choisir."
        },
        {
            "start": 996,
            "end": 1007,
            "text": "Par exemple, on pourrait prendre la classe des fonctions lin\u00e9aires ou d'autres classes de fonctions, plus un terme r\u00e9siduel."
        },
        {
            "start": 1007,
            "end": 1015,
            "text": "Donc la question fondamentale de l'apprentissage supervis\u00e9, c'est comment choisir F ?"
        },
        {
            "start": 1015,
            "end": 1021,
            "text": "Juste quelques remarques importantes sur l'apprentissage supervis\u00e9, des choses \u00e0 retenir."
        },
        {
            "start": 1021,
            "end": 1030,
            "text": "La seule observation dont on dispose, c'est l'ensemble des couples XY, c'est notre \u00e9chantillon, notre ensemble d'apprentissage D est inconnu."
        },
        {
            "start": 1030,
            "end": 1038,
            "text": "Je viens de le dire, cet \u00e9chantillon, cet ensemble C, c'est ce qu'on appelle l'ensemble d'apprentissage."
        },
        {
            "start": 1038,
            "end": 1047,
            "text": "Donc X, \u00e7a appartient \u00e0 grand X, et en g\u00e9n\u00e9ral, on prend une repr\u00e9sentation vectoriale, donc X est inclus dans grand Rd."
        },
        {
            "start": 1047,
            "end": 1064,
            "text": "Dans notre cas, X, \u00e7a va consister en un document, et on va repr\u00e9senter ce document par un vecteur dans l'espace vectorial des termes, en utilisant la repr\u00e9sentation sac de mots qu'on a introduit plus t\u00f4t dans le cours."
        },
        {
            "start": 1064,
            "end": 1074,
            "text": "Y, \u00e7a appartient \u00e0 Y, et par exemple, si on a un probl\u00e8me de cat\u00e9gorisation binaire, on consid\u00e8re souvent que Y, c'est moins un ou plus un."
        },
        {
            "start": 1074,
            "end": 1078,
            "text": "Dans notre cas, c'est assez facile de se ramener \u00e0 un probl\u00e8me de cat\u00e9gorisation binaire."
        },
        {
            "start": 1078,
            "end": 1084,
            "text": "Typiquement, on peut vouloir classer les documents en documents pertinents versus documents non pertinents."
        },
        {
            "start": 1084,
            "end": 1091,
            "text": "On classe la classe des documents pertinents versus la classe des documents non pertinents."
        },
        {
            "start": 1091,
            "end": 1094,
            "text": "Revenons \u00e0 l'objectif de l'apprentissage supervis\u00e9."
        },
        {
            "start": 1094,
            "end": 1110,
            "text": "On l'a dit tout \u00e0 l'heure, on cherche \u00e0 construire une fonction F \u00e0 partir des n donn\u00e9es d'apprentissage, telle que F va pr\u00e9dire la sortie Y associ\u00e9e \u00e0 une donn\u00e9e X. Quelles sont les propri\u00e9t\u00e9s voulues de F ?"
        },
        {
            "start": 1110,
            "end": 1113,
            "text": "Quelles sont les propri\u00e9t\u00e9s de cette fonction F ?"
        },
        {
            "start": 1113,
            "end": 1123,
            "text": "La premi\u00e8re propri\u00e9t\u00e9 relativement intuitive, c'est bien s\u00fbr que F doit pr\u00e9dire les bonnes valeurs pour l'ensemble des donn\u00e9es de notre ensemble d'apprentissage."
        },
        {
            "start": 1123,
            "end": 1144,
            "text": "Quelles que soient XI et Y dans C, F de XI doit \u00eatre \u00e9gal \u00e0 Y. L'autre propri\u00e9t\u00e9 fondamentale en apprentissage automatique, c'est que F doit aussi pouvoir pr\u00e9dire les bonnes sorties pour des exemples futurs XJ, c'est-\u00e0-dire pour des donn\u00e9es X qui n'appartiennent pas \u00e0 l'ensemble d'apprentissage."
        },
        {
            "start": 1144,
            "end": 1148,
            "text": "C'est ce qu'on conna\u00eet sous le probl\u00e8me de la g\u00e9n\u00e9ration de donn\u00e9es."
        },
        {
            "start": 1148,
            "end": 1155,
            "text": "Juste quelques illustrations, et notamment selon l'axe type de probl\u00e8me \u00e0 traiter."
        },
        {
            "start": 1155,
            "end": 1167,
            "text": "Si Y est \u00e0 valeur r\u00e9elle, c'est-\u00e0-dire que Y est \u00e9gal \u00e0 Rm, alors on est dans ce cas-l\u00e0, on est dans un cas de r\u00e9gr\u00e9gation de la valeur de la donn\u00e9e."
        },
        {
            "start": 1167,
            "end": 1174,
            "text": "On a donc un X qui est \u00e9gal \u00e0 Rm, et on a un X qui est \u00e9gal \u00e0 Rm."
        },
        {
            "start": 1174,
            "end": 1178,
            "text": "On est dans un cas de r\u00e9gression."
        },
        {
            "start": 1178,
            "end": 1183,
            "text": "Ici, on a une illustration d'un probl\u00e8me de r\u00e9gression."
        },
        {
            "start": 1183,
            "end": 1198,
            "text": "On a les points noirs qui sont nos donn\u00e9es d'apprentissage, on a la vraie fonction, et ce qu'on cherche \u00e0 construire, c'est une fonction F de X qui va \u00eatre la plus proche possible de la fonction en bleu."
        },
        {
            "start": 1198,
            "end": 1204,
            "text": "Qui va \u00eatre une bonne estimation de cette fonction en bleu qui repr\u00e9sente la vraie fonction."
        },
        {
            "start": 1204,
            "end": 1212,
            "text": "Quand on est sur un probl\u00e8me de classification, XI va \u00eatre associ\u00e9 \u00e0 une sortie cat\u00e9goriale."
        },
        {
            "start": 1212,
            "end": 1216,
            "text": "On voit ici une illustration d'un probl\u00e8me o\u00f9 on a deux classes."
        },
        {
            "start": 1216,
            "end": 1220,
            "text": "Un probl\u00e8me de classification binaire, les points noirs et les points rouges."
        },
        {
            "start": 1220,
            "end": 1224,
            "text": "Ici, on est sur un probl\u00e8me de classification \u00e0 trois classes."
        },
        {
            "start": 1224,
            "end": 1228,
            "text": "On voit bien les classes qui sont bien s\u00e9par\u00e9es."
        },
        {
            "start": 1228,
            "end": 1236,
            "text": "Dans ce cas-l\u00e0, on va parler de classification."
        },
        {
            "start": 1236,
            "end": 1259,
            "text": "Supposons qu'on a notre fonction F On peut se poser des questions sur la qualit\u00e9 de cette fonction F Pour \u00e7a, on va s'\u00e9quiper d'une fonction de co\u00fbt, qu'on appelle la fonction de co\u00fbt aussi la loss function et donc qui est un \u00e9l\u00e9ment cl\u00e9 de la th\u00e9orie de l'apprentissage, de comment fonctionne l'apprentissage supervis\u00e9."
        },
        {
            "start": 1259,
            "end": 1263,
            "text": "Et notamment cette fonction de coup, elle doit permettre de p\u00e9naliser les erreurs."
        },
        {
            "start": 1263,
            "end": 1284,
            "text": "Typiquement, cette fonction de coup, elle doit p\u00e9naliser le cas o\u00f9 on va avoir une pr\u00e9diction Y, chapeau, donc Y chapeau qui est \u00e9gale \u00e0 f de X, qui est diff\u00e9rente du vrai Y que l'on conna\u00eet, donc dans les donn\u00e9es qu'on a dans notre ensemble d'apprentissage."
        },
        {
            "start": 1284,
            "end": 1306,
            "text": "Voil\u00e0 donc une fonction de coup, c'est une fonction L qui va de Y dans R plus, telle que L de Y qui va \u00eatre sup\u00e9r\u00e9e \u00e0 z\u00e9ro pour toute Y qui est diff\u00e9rente de Y. Donc ce qu'on veut au travers de cette fonction de coup, bien s\u00fbr, c'est que le co\u00fbt d'une bonne pr\u00e9diction soit plus faible que le co\u00fbt d'une erreur."
        },
        {
            "start": 1306,
            "end": 1312,
            "text": "Alors il existe \u00e9norm\u00e9ment de fonctions de coup possibles."
        },
        {
            "start": 1312,
            "end": 1334,
            "text": "Si par exemple on se rapporte \u00e0 un probl\u00e8me de classification, on a un co\u00fbt qui est tr\u00e8s connu, qui est le co\u00fbt 0,1, o\u00f9 on va avoir un co\u00fbt de z\u00e9ro si Y est \u00e9gal \u00e0 f de X, donc si Y est \u00e9gal \u00e0 f de X, c'est-\u00e0-dire si on a une bonne pr\u00e9diction et un sinon."
        },
        {
            "start": 1334,
            "end": 1352,
            "text": "Typiquement, ce co\u00fbt 0,1, il consiste \u00e0 mesurer le nombre de points qui est mal class\u00e9 par la fonction f. Donc l\u00e0, \u00e7a devient int\u00e9ressant et on rentre un petit peu plus dans la th\u00e9orie de l'apprentissage supervis\u00e9, notamment en introduisant la minimisation du risque."
        },
        {
            "start": 1352,
            "end": 1368,
            "text": "Donc ce qu'on souhaite, c'est construire une fonction f \u00e0 partir de n donn\u00e9es, donc nos donn\u00e9es d'apprentissage, et ce qu'on veut c'est que f donne des bonnes approximations sur ces n donn\u00e9es et aussi sur les donn\u00e9es futures."
        },
        {
            "start": 1368,
            "end": 1383,
            "text": "Donc en fait, ce qu'on cherche \u00e0 faire, c'est minimiser le risque, ou risque fonctionnel ou erreur de g\u00e9n\u00e9ralisation, qui est finalement l'esp\u00e9rance de notre fonction de coup L, par rapport \u00e0 XY bien s\u00fbr."
        },
        {
            "start": 1383,
            "end": 1397,
            "text": "Donc ce risque fonctionnel, c'est l'esp\u00e9rance, donc selon la distribution de probabilit\u00e9s jointes P du XY, de notre fonction de coup L. \u00c7a, \u00e7a repr\u00e9sente en moyenne le co\u00fbt pour toutes les donn\u00e9es possibles."
        },
        {
            "start": 1397,
            "end": 1401,
            "text": "Et donc c'est l\u00e0 que \u00e7a devient compliqu\u00e9, parce qu'on n'a pas toutes les donn\u00e9es."
        },
        {
            "start": 1401,
            "end": 1404,
            "text": "Il est impossible d'avoir toutes les donn\u00e9es possibles."
        },
        {
            "start": 1404,
            "end": 1428,
            "text": "Par contre, ce qu'on a, c'est notre ensemble d'apprentissages C. C'est notre \u00e9chantillon, et donc sur cet ensemble d'\u00e9chantillons C, on peut bien s\u00fbr calculer et mesurer le risque empirique, qui est donc la moyenne pour l'ensemble des donn\u00e9es d'apprentissage de ce que donne la fonction de coup sur ces donn\u00e9es d'apprentissage."
        },
        {
            "start": 1428,
            "end": 1434,
            "text": "Et ce qu'on cherche \u00e0 faire, c'est minimiser le risque."
        },
        {
            "start": 1434,
            "end": 1446,
            "text": "Donc est-ce qu'on peut se contenter de minimiser, de chercher F, parmi une classe d'hypoth\u00e8ses, parmi un ensemble de fonctions F ?"
        },
        {
            "start": 1446,
            "end": 1455,
            "text": "Ce qu'on va chercher \u00e0 faire, c'est trouver la fonction F qui va minimiser le risque."
        },
        {
            "start": 1455,
            "end": 1468,
            "text": "Donc comme on n'a que le risque empirique, est-ce qu'on peut se contenter finalement de chercher la fonction F, parmi notre classe d'hypoth\u00e8ses, qui va minimiser le risque empirique ?"
        },
        {
            "start": 1468,
            "end": 1471,
            "text": "La r\u00e9ponse \u00e0 cette question, c'est non."
        },
        {
            "start": 1471,
            "end": 1472,
            "text": "Pourquoi ?"
        },
        {
            "start": 1472,
            "end": 1484,
            "text": "Parce qu'en fait le risque empirique, il ne va pas permettre d'\u00e9valuer la pertinence du mod\u00e8le, parce que typiquement on peut tomber dans des probl\u00e8mes qu'on appelle des probl\u00e8mes de surapprentissage."
        },
        {
            "start": 1484,
            "end": 1494,
            "text": "C'est-\u00e0-dire qu'on va pouvoir, en minimisant le risque empirique, choisir une fonction F telle que le risque empirique va \u00eatre tr\u00e8s bas, voire nul."
        },
        {
            "start": 1494,
            "end": 1505,
            "text": "Et notamment, plus on prend une fonction F qui va \u00eatre complexe et qui va du coup fiter les donn\u00e9es, plus on va \u00eatre dans ce cas-l\u00e0."
        },
        {
            "start": 1505,
            "end": 1517,
            "text": "Mais par contre, sur de nouvelles donn\u00e9es, donc sur un ensemble de tests, ce risque, l'erreur de g\u00e9n\u00e9ralisation, elle va \u00eatre tr\u00e8s \u00e9lev\u00e9e."
        },
        {
            "start": 1517,
            "end": 1519,
            "text": "L'erreur de pr\u00e9diction, elle va \u00eatre \u00e9lev\u00e9e."
        },
        {
            "start": 1519,
            "end": 1528,
            "text": "Donc \u00e7a, c'est typiquement un cas tr\u00e8s connu en apprentissage, qui s'appelle le cas du surapprentissage."
        },
        {
            "start": 1528,
            "end": 1549,
            "text": "Donc la solution, en fait, \u00e7a va \u00eatre de minimiser le risque empirique, donc \u00e0 partir de notre \u00e9chantillon d'apprentissage, et on va rajouter \u00e0 ce risque empirique, en fait, un terme qu'on va appeler un terme de r\u00e9gularisation, qui va donc permettre la g\u00e9n\u00e9ralisation du mod\u00e8le d'apprentissage."
        },
        {
            "start": 1549,
            "end": 1565,
            "text": "Donc \u00e7a, c'est vraiment ce qu'a montr\u00e9 la th\u00e9orie de Vapnik, que la construction d'une fonction d'apprentissage, on peut la formaliser comme un probl\u00e8me de minimisation."
        },
        {
            "start": 1565,
            "end": 1584,
            "text": "Donc parmi une famille de fonctions qu'on appelle les classes d'hypoth\u00e8ses, chercher F appartenant \u00e0 F, qui va minimiser le risque empirique r\u00e9gularis\u00e9, donc avec un facteur de r\u00e9gularisation lambda."
        },
        {
            "start": 1584,
            "end": 1588,
            "text": "Voil\u00e0, donc, rapide bilan sur l'apprentissage supervis\u00e9."
        },
        {
            "start": 1588,
            "end": 1593,
            "text": "Un algorithme d'apprentissage a un ensemble de fonctions F, donc \u00e7a, c'est notre classe d'hypoth\u00e8ses."
        },
        {
            "start": 1593,
            "end": 1605,
            "text": "Par exemple, vous pouvez prendre l'ensemble des fonctions lin\u00e9aires, l'ensemble des fonctions de type r\u00e9seau de neurones, enfin voil\u00e0, on a ce qu'on appelle une classe d'hypoth\u00e8ses."
        },
        {
            "start": 1605,
            "end": 1631,
            "text": "Et ce que fait cet algorithme d'apprentissage, c'est qu'il va s\u00e9lectionner parmi cet ensemble de fonctions, la fonction la plus appropri\u00e9e, donc en utilisant l'ensemble d'apprentissage, donc la minimisation du risque empirique, et la fonction objective, donc notre fonction de co\u00fbt, avec bien s\u00fbr ajout\u00e9 \u00e0 ce risque empirique une fonction de r\u00e9gularisation qui, elle, est d\u00e9finie par l'utilisateur."
        },
        {
            "start": 1631,
            "end": 1652,
            "text": "Ensuite, cet algorithme d'apprentissage, il va r\u00e9aliser la s\u00e9lection de F, donc avec des m\u00e9thodes qui lui sont propres, qui sont souvent des techniques qui font appel \u00e0 des techniques d'optimisation, type des centres de gradients, par exemple, pour les r\u00e9seaux de neurones, passage au lagrangien pour les SVM, etc."
        },
        {
            "start": 1652,
            "end": 1662,
            "text": "Voil\u00e0, et un aspect important, en fait, de l'apprentissage dont je n'ai pas parl\u00e9, c'est la repr\u00e9sentation des exemples, c'est ce qu'on va donner en entr\u00e9e, finalement, de notre syst\u00e8me d'apprentissage."
        },
        {
            "start": 1662,
            "end": 1679,
            "text": "Donc \u00e7a, c'est typiquement une probl\u00e9matique qu'on appelle la probl\u00e9matique du feature engineering et qu'on oppose aujourd'hui aux approches qu'on appelle de repr\u00e9sentation learning, o\u00f9, en fait, on va apprendre aussi une repr\u00e9sentation de nos exemples, et c'est typiquement ce que permet de faire des approches de type apprentissage profond."
        },
        {
            "start": 1679,
            "end": 1684,
            "text": "Mais \u00e7a, c'est hors sujet, en fait, de type apprentissage profond."
        },
        {
            "start": 1684,
            "end": 1689,
            "text": "Mais \u00e7a, c'est hors sujet pour ce cours, aujourd'hui, en tout cas."
        },
        {
            "start": 1689,
            "end": 1701,
            "text": "Voil\u00e0, donc maintenant, on va revenir \u00e0 notre probl\u00e8me de recherche d'informations et on va s'int\u00e9resser plus sp\u00e9cifiquement \u00e0 des probl\u00e8mes de cat\u00e9gorisation et le lien avec la recherche d'informations."
        },
        {
            "start": 1701,
            "end": 1706,
            "text": "Donc, on va prendre comme exemple le probl\u00e8me de la cat\u00e9gorisation de documents."
        },
        {
            "start": 1706,
            "end": 1711,
            "text": "Donc, on peut tr\u00e8s facilement illustrer sous la forme de ce sch\u00e9ma-l\u00e0."
        },
        {
            "start": 1711,
            "end": 1721,
            "text": "Donc, on a nos deux phases classiques dans les syst\u00e8mes d'apprentissage, une phase d'entra\u00eenement du mod\u00e8le et une phase de pr\u00e9diction."
        },
        {
            "start": 1721,
            "end": 1726,
            "text": "Voil\u00e0, donc on a une collection de documents qui est labellis\u00e9e, \u00e9tiquet\u00e9e."
        },
        {
            "start": 1726,
            "end": 1730,
            "text": "Donc, pour chaque document, on a un ensemble d'\u00e9tiquettes."
        },
        {
            "start": 1730,
            "end": 1736,
            "text": "Les documents, donc, il y a toutes les tables de construction de feature engineering."
        },
        {
            "start": 1736,
            "end": 1743,
            "text": "Donc, typiquement, les documents, on va les repr\u00e9senter sous la forme de documents vectoris\u00e9s."
        },
        {
            "start": 1743,
            "end": 1752,
            "text": "Donc, par exemple, avec des repr\u00e9sentations TFIDF dans l'espace des termes du vocabulaire qu'on a construit sur la collection."
        },
        {
            "start": 1752,
            "end": 1766,
            "text": "Et puis, comme on a donc nos donn\u00e9es labellis\u00e9es, comme on a des \u00e9tiquettes, on va donc apprendre un mod\u00e8le de cat\u00e9gorisation sur ces donn\u00e9es-l\u00e0."
        },
        {
            "start": 1766,
            "end": 1775,
            "text": "Et puis, maintenant, on peut utiliser ce mod\u00e8le dans une phase de pr\u00e9diction pour un nouveau document test que je d\u00e9cris de la m\u00eame mani\u00e8re, bien s\u00fbr."
        },
        {
            "start": 1775,
            "end": 1779,
            "text": "Donc, je construis aussi une repr\u00e9sentation vectoris\u00e9e de mon document."
        },
        {
            "start": 1779,
            "end": 1785,
            "text": "J'utilise mon classifieur et je pr\u00e9dis donc une \u00e9tiquette pour des primes."
        },
        {
            "start": 1785,
            "end": 1796,
            "text": "Alors, si je d\u00e9finis \u00e7a de mani\u00e8re un peu plus formelle, je vais consid\u00e9rer un espace de repr\u00e9sentation pour mes documents quantiques."
        },
        {
            "start": 1796,
            "end": 1805,
            "text": "J'ai un ensemble de classes fix\u00e9es C, qui sont les diff\u00e9rentes cat\u00e9gories possibles pour mon document, donc l'ensemble des classes qui sont les classes d'\u00e9tiquettes."
        },
        {
            "start": 1805,
            "end": 1812,
            "text": "Et puis, j'ai donc mon ensemble d'apprentissages D qui est compos\u00e9 de paires D et C, les \u00e9tiquettes associ\u00e9es."
        },
        {
            "start": 1812,
            "end": 1819,
            "text": "Et puis, il va suffire d'apprendre une fonction F, un classifieur qui va associer les documents \u00e0 sa classe ou \u00e0 leur classe."
        },
        {
            "start": 1819,
            "end": 1822,
            "text": "Alors, \u00e7a peut \u00eatre un probl\u00e8me de classification multiclasse."
        },
        {
            "start": 1822,
            "end": 1823,
            "text": "Voil\u00e0."
        },
        {
            "start": 1823,
            "end": 1841,
            "text": "Alors, juste faites attention parce que ici j'ai chang\u00e9 mes notations et notamment C ici est mon ensemble de classes et non plus mon ensemble d'apprentissages et D n'est plus ma distribution de probabilit\u00e9s inconnues, mais c'est mon ensemble d'apprentissages."
        },
        {
            "start": 1841,
            "end": 1844,
            "text": "Je suis d\u00e9sol\u00e9e pour ce petit changement, donc j'insiste bien l\u00e0-dessus."
        },
        {
            "start": 1844,
            "end": 1848,
            "text": "Attention aux changements de notation par rapport aux slides pr\u00e9c\u00e9dentes."
        },
        {
            "start": 1848,
            "end": 1848,
            "text": "Voil\u00e0."
        },
        {
            "start": 1848,
            "end": 1856,
            "text": "Alors, il y a plein d'applications, en fait, de la cat\u00e9gorisation de documents pour la recherche d'informations."
        },
        {
            "start": 1856,
            "end": 1859,
            "text": "Il y a \u00e9norm\u00e9ment d'applications possibles."
        },
        {
            "start": 1859,
            "end": 1873,
            "text": "Par exemple, on a vu que toutes les techniques d'indexation \u00e9taient d\u00e9pendantes de la langue, ne serait-ce que l'\u00e9tape de tokenisation, m\u00eame si aujourd'hui il existe des tokenizers qui sont langages ind\u00e9pendants."
        },
        {
            "start": 1873,
            "end": 1884,
            "text": "Et du coup, il est souvent n\u00e9cessaire, \u00e9tant donn\u00e9 un document, d'identifier sa langue pour justement appliquer la bonne cha\u00eene de traitement linguistique."
        },
        {
            "start": 1884,
            "end": 1886,
            "text": "Eh bien, \u00e7a c'est un probl\u00e8me de cat\u00e9gorisation."
        },
        {
            "start": 1886,
            "end": 1896,
            "text": "L'ensemble des classes, c'est l'ensemble des langages du corpus, et puis ce qu'il faut, c'est \u00e9tant donn\u00e9 un document, pr\u00e9dire la langue du document."
        },
        {
            "start": 1896,
            "end": 1913,
            "text": "On peut aussi utiliser ce principe de cat\u00e9gorisation, par exemple dans le cas du web, pour d\u00e9tecter des pages qui sont des spams ou des pages qui sont des non-spams, et notamment pour \u00e9viter d'avoir \u00e0 indexer des pages qui sont des pages de type spam."
        },
        {
            "start": 1913,
            "end": 1925,
            "text": "Voil\u00e0, alors d'autres applications assez connues, c'est par exemple tout ce qui est d\u00e9tection de sentiments dans des donn\u00e9es qui sont des donn\u00e9es de r\u00e9seaux sociaux, voil\u00e0, type tweet, etc."
        },
        {
            "start": 1925,
            "end": 1934,
            "text": "Voil\u00e0, alors en recherche d'informations, une application aussi assez classique de la cat\u00e9gorisation de documents, c'est la d\u00e9tection de th\u00e9matiques ou la recherche de verticaux."
        },
        {
            "start": 1934,
            "end": 1949,
            "text": "Typiquement, dans les moteurs de recherche grand public, ce qu'on appelle un vertical ou les verticaux, c'est typiquement par exemple de limiter une recherche par exemple \u00e0 l'ensemble des actualit\u00e9s, ou \u00e0 l'ensemble des images, ou \u00e0 l'ensemble des vid\u00e9os."
        },
        {
            "start": 1949,
            "end": 1951,
            "text": "\u00c7a c'est des verticaux."
        },
        {
            "start": 1951,
            "end": 1961,
            "text": "Et donc, associer un document au type de vertical recherch\u00e9, ou quel il correspond, \u00e7a c'est un probl\u00e8me de classification."
        },
        {
            "start": 1961,
            "end": 1974,
            "text": "Voil\u00e0, alors on va du coup maintenant s'int\u00e9resser \u00e0 quelques algorithmes de cat\u00e9gorisation qui sont un peu les algorithmes historiques qu'on utilise pour la recherche d'informations."
        },
        {
            "start": 1974,
            "end": 1985,
            "text": "Voil\u00e0, il y a deux grandes familles d'algorithmes de cat\u00e9gorisation selon le type finalement de mod\u00e8les qu'on utilise."
        },
        {
            "start": 1985,
            "end": 1992,
            "text": "Il y a notamment des algorithmes qui sont des algorithmes qui font partie des mod\u00e8les qu'on appelle les mod\u00e8les g\u00e9n\u00e9ratifs."
        },
        {
            "start": 1992,
            "end": 1999,
            "text": "\u00c7a c'est typiquement les premiers mod\u00e8les d'apprentissage qui ont \u00e9t\u00e9 d\u00e9velopp\u00e9s pour la cat\u00e9gorisation de documents."
        },
        {
            "start": 1999,
            "end": 2030,
            "text": "Ces mod\u00e8les g\u00e9n\u00e9ratifs, en fait, ils se basent sur l'hypoth\u00e8se qui est \u00e9crite sur cette slide, qui consiste \u00e0 dire que chaque vecteur repr\u00e9sentatif d'un document D, on va le mod\u00e9liser comme la r\u00e9alisation d'une variable al\u00e9atoire multidimensionnelle, qui est g\u00e9n\u00e9r\u00e9e par le m\u00e9lange de cas densit\u00e9 de probabilit\u00e9 avec des proportions pica telles que la somme des pica pour l'ensemble des cas densit\u00e9 est \u00e9gale \u00e0 1."
        },
        {
            "start": 2030,
            "end": 2035,
            "text": "Et puis bien s\u00fbr pica c'est sup\u00e9rieur \u00e0 0."
        },
        {
            "start": 2035,
            "end": 2043,
            "text": "Donc typiquement, k c'est typiquement les diff\u00e9rentes classes possibles."
        },
        {
            "start": 2043,
            "end": 2060,
            "text": "Un exemple d'algorithme ou de m\u00e9thode de cat\u00e9gorisation qui fait partie de ces mod\u00e8les g\u00e9n\u00e9ratifs, c'est par exemple le classif\u00e8re Bayesien qui utilise du coup la r\u00e8gle de Bayes, le classif\u00e8re qu'on appelle le classif\u00e8re Bayesien na\u00eff."
        },
        {
            "start": 2060,
            "end": 2087,
            "text": "On peut aussi proposer des approches pour la cat\u00e9gorisation en utilisant des mod\u00e8les qu'on appelle les mod\u00e8les discriminants, qui eux vont directement trouver une fonction de classification F donc de grand Rd, qui est l'espace de repr\u00e9sentation de nos documents, dans grand Y et qui va r\u00e9soudre le probl\u00e8me de cat\u00e9gorisation sans faire d'hypoth\u00e8ses sur la mani\u00e8re dont sont g\u00e9n\u00e9r\u00e9s les exemples."
        },
        {
            "start": 2087,
            "end": 2097,
            "text": "Donc une fa\u00e7on un peu d'illustrer la diff\u00e9rence entre ces deux cat\u00e9gories de mod\u00e8les."
        },
        {
            "start": 2097,
            "end": 2121,
            "text": "Ici le mod\u00e8le g\u00e9n\u00e9ratif c'est vraiment le mod\u00e8le du peintre qui va typiquement essayer de reproduire au mieux le processus de g\u00e9n\u00e9ration de donn\u00e9es et ici c'est l'approche du caricaturiste qui va grossi\u00e8rement tracer les traits discriminants des donn\u00e9es."
        },
        {
            "start": 2121,
            "end": 2140,
            "text": "Alors un exemple d'approche de classification qui fait partie des mod\u00e8les discriminants c'est par exemple les SVM qui sont les s\u00e9parateurs \u00e0 vaste marge ou d'autres approches comme les capes le proche voisin ou le perceptron, des approches de r\u00e9gression logistique etc."
        },
        {
            "start": 2140,
            "end": 2143,
            "text": "Ce sont des mod\u00e8les discriminants."
        },
        {
            "start": 2143,
            "end": 2151,
            "text": "On va s'int\u00e9resser dans un premier temps \u00e0 des mod\u00e8les g\u00e9n\u00e9ratifs donc assez classiques en recherche d'informations."
        },
        {
            "start": 2151,
            "end": 2155,
            "text": "Notamment on va s'int\u00e9resser au classifieur Bayesian."
        },
        {
            "start": 2155,
            "end": 2178,
            "text": "Pour vous introduire ce classifieur Bayesian, je vais utiliser un exemple qui vient d'un tr\u00e8s bon cours d'apprentissage de Gilles Gassot o\u00f9 on prend un probl\u00e8me de classification jouet qui consiste \u00e0 classer un fruit comme en deux classes possibles comme poire donc \u00e7a c'est la classe C1 ou p\u00eache c'est la classe C2."
        },
        {
            "start": 2178,
            "end": 2195,
            "text": "Alors on peut classer un fruit donn\u00e9 qui est donc une donn\u00e9e d'entr\u00e9e en utilisant une probabilit\u00e9 a priori qui refl\u00e8terait notre connaissance qu'un fruit soit une poire ou une p\u00eache sans qu'on ait observ\u00e9 le dit fruit."
        },
        {
            "start": 2195,
            "end": 2220,
            "text": "Par exemple voil\u00e0 je regarde mon contexte je sais que nous sommes au mois de mai et donc voil\u00e0 ma connaissance me dit que la probabilit\u00e9 que le fruit soit une p\u00eache elle est plus forte que le fruit soit une poire selon l'aspect saisonnalit\u00e9."
        },
        {
            "start": 2220,
            "end": 2244,
            "text": "Donc on a bien s\u00fbr ces propri\u00e9t\u00e9s sur les probabilit\u00e9s a priori la probabilit\u00e9 a priori d'\u00eatre une poire plus la probabilit\u00e9 a priori d'\u00eatre une p\u00eache elle est \u00e9gale \u00e0 1 et puis du coup je peux utiliser ces probabilit\u00e9s a priori pour mon probl\u00e8me de classification."
        },
        {
            "start": 2244,
            "end": 2257,
            "text": "Typiquement je vais affecter le fruit \u00e0 la classe 1 si la probabilit\u00e9 a priori d'\u00eatre de la classe 1 donc d'\u00eatre une poire elle est plus grande que la probabilit\u00e9 a priori d'\u00eatre de la classe C donc d'\u00eatre une p\u00eache."
        },
        {
            "start": 2257,
            "end": 2267,
            "text": "On voit qu'en faisant \u00e7a donc sans prendre en compte les caract\u00e9ristiques intrins\u00e8ques des donn\u00e9es je risque d'avoir un risque d'erreur qui va \u00eatre important."
        },
        {
            "start": 2267,
            "end": 2279,
            "text": "Et donc pour contrabalancer \u00e7a l'id\u00e9e \u00e7a va \u00eatre de prendre en compte les caract\u00e9ristiques intrins\u00e8ques des donn\u00e9es de notre fruit et donc de passer par cette \u00e9tape de repr\u00e9sentation."
        },
        {
            "start": 2279,
            "end": 2289,
            "text": "De d\u00e9finir un ensemble de caract\u00e9ristiques X qui vont appartenir \u00e0 RDR et qui vont repr\u00e9senter le fruit comme par exemple sa forme sa couleur son odeur etc."
        },
        {
            "start": 2289,
            "end": 2296,
            "text": "Des choses qui vont caract\u00e9riser un ensemble d'observations sur l'objet qu'on cherche \u00e0 classifier."
        },
        {
            "start": 2296,
            "end": 2302,
            "text": "Et puis du coup je vais d\u00e9finir des lois conditionnelles pour les diff\u00e9rentes classes."
        },
        {
            "start": 2302,
            "end": 2313,
            "text": "Donc mes deux classes C1 poire C2 p\u00eache donc P de X sachant C1 et P de X sachant C2."
        },
        {
            "start": 2313,
            "end": 2325,
            "text": "Typiquement une illustration possible de ces lois conditionnelles avec en rouge la classe C1 et en bleu la classe C2."
        },
        {
            "start": 2325,
            "end": 2347,
            "text": "Du coup je vais en utilisant le th\u00e9or\u00e8me de Bayes pouvoir calculer la probabilit\u00e9 a posteriori de ces cas sachant X. Cette probabilit\u00e9 a posteriori je l'obtiens avec le th\u00e9or\u00e8me de Bayes et il m'est fourni par cette \u00e9quation."
        },
        {
            "start": 2347,
            "end": 2360,
            "text": "P de X sachant C4 fois la probabilit\u00e9 a priori de ces cas sur la somme entre P de X sachant C1 probabilit\u00e9 a priori de C1 plus P de X sachant C2 plus la probabilit\u00e9 a priori de C2."
        },
        {
            "start": 2360,
            "end": 2363,
            "text": "\u00c7a c'est le th\u00e9or\u00e8me de Bayes."
        },
        {
            "start": 2363,
            "end": 2376,
            "text": "Et en utilisant du coup ces probabilit\u00e9s a posteriori je vais avoir une nouvelle r\u00e8gle de d\u00e9cision qui va consister \u00e0 affecter X \u00e0 la classe de plus forte probabilit\u00e9 a posteriori."
        },
        {
            "start": 2376,
            "end": 2392,
            "text": "Donc si la probabilit\u00e9 a posteriori de poire sachant X est plus grande \u00e0 la probabilit\u00e9 a posteriori de p\u00eache sachant X alors X est de la classe poire c'est une instance de poire."
        },
        {
            "start": 2392,
            "end": 2399,
            "text": "Donc je d\u00e9finis ainsi avec cette r\u00e8gle de d\u00e9cision une fronti\u00e8re de d\u00e9cision."
        },
        {
            "start": 2399,
            "end": 2401,
            "text": "On va l'appeler une fronti\u00e8re de d\u00e9cision."
        },
        {
            "start": 2401,
            "end": 2411,
            "text": "Puis typiquement je vais pouvoir qualifier cette fronti\u00e8re de d\u00e9cision justement en regardant comment \u00e7a se comporte sur sur des donn\u00e9es de test."
        },
        {
            "start": 2411,
            "end": 2420,
            "text": "Typiquement en regardant le taux d'erreur c'est \u00e0 dire le nombre de mod\u00e8les de mauvaise d\u00e9cision sur le nombre total de d\u00e9cisions."
        },
        {
            "start": 2420,
            "end": 2428,
            "text": "Voil\u00e0 donc la d\u00e9marche qu'on va mettre en oeuvre pour des mod\u00e8les g\u00e9n\u00e9ratifs de type classif eurb\u00e9gien."
        },
        {
            "start": 2428,
            "end": 2432,
            "text": "C'est celle que je vais pr\u00e9senter juste maintenant."
        },
        {
            "start": 2432,
            "end": 2439,
            "text": "J'observe un ensemble de caract\u00e9ristiques not\u00e9es X qui d\u00e9crivent une entit\u00e9."
        },
        {
            "start": 2439,
            "end": 2448,
            "text": "Je suppose qu'une entit\u00e9 provient d'une classe donn\u00e9e et je vais prendre une d\u00e9cision en fonction de l'observation de ces caract\u00e9ristiques."
        },
        {
            "start": 2448,
            "end": 2458,
            "text": "Chaque d\u00e9cision, action, va donc avoir un certain co\u00fbt en fonction de la classe \u00e0 laquelle appartient X."
        },
        {
            "start": 2458,
            "end": 2470,
            "text": "Et puis l'objectif du classif eurb\u00e9gien \u00e7a va \u00eatre de trouver une r\u00e8gle de d\u00e9cision qui va minimiser un co\u00fbt moyen d\u00e9finissant quelles d\u00e9cisions prendre en fonction de l'entit\u00e9 observ\u00e9e."
        },
        {
            "start": 2470,
            "end": 2476,
            "text": "On retrouve ici les objectifs de notre apprentissage au supervis\u00e9."
        },
        {
            "start": 2476,
            "end": 2479,
            "text": "Quelques notations qui vont \u00eatre utiles pour la suite."
        },
        {
            "start": 2479,
            "end": 2492,
            "text": "On a un ensemble de classes C1, C4, de probabilit\u00e9 a priori PR de CK, c'est \u00e0 dire la probabilit\u00e9 que C est \u00e9gale \u00e0 CK pour chaque classe."
        },
        {
            "start": 2492,
            "end": 2497,
            "text": "On a donc un espace de caract\u00e9ristiques X. Typiquement X peut \u00eatre \u00e9gal \u00e0 Rd."
        },
        {
            "start": 2497,
            "end": 2509,
            "text": "Et puis on a donc la probabilit\u00e9 \u00e0... a posteriori, la probabilit\u00e9 que C est \u00e9gale \u00e0 CK, sachant que X est \u00e9gale \u00e0 X."
        },
        {
            "start": 2509,
            "end": 2512,
            "text": "On va noter P de CK sachant X."
        },
        {
            "start": 2512,
            "end": 2528,
            "text": "La loi conditionnelle de X \u00e0 la classe CK, c'est la probabilit\u00e9 de X sachant CK, c'est \u00e9gal \u00e0 la probabilit\u00e9 que la variable al\u00e9atoire X prenne la valeur X, sachant que la classe C est \u00e9gale \u00e0 CK."
        },
        {
            "start": 2528,
            "end": 2534,
            "text": "La loi marginale de X, on va la d\u00e9finir sur l'ensemble des classes possibles."
        },
        {
            "start": 2534,
            "end": 2551,
            "text": "C'est la somme pour l'ensemble des classes possibles de la loi conditionnelle de X \u00e0 la classe CK fois la probabilit\u00e9 a priori de CK."
        },
        {
            "start": 2551,
            "end": 2560,
            "text": "Le probl\u00e8me, \u00e7a va \u00eatre trouver la classe de X par une approche probabiliste en utilisant le maximum a posteriori."
        },
        {
            "start": 2560,
            "end": 2572,
            "text": "La classe pour X, \u00e7a va \u00eatre la classe qui va permettre de maximiser cette quantit\u00e9-l\u00e0."
        },
        {
            "start": 2572,
            "end": 2578,
            "text": "La remax selon K de cette quantit\u00e9-l\u00e0."
        },
        {
            "start": 2578,
            "end": 2594,
            "text": "Ce qu'il va falloir faire pour mettre en \u0153uvre le classifiant ab\u00e9zien, \u00e7a va \u00eatre d'estimer les quantit\u00e9s de cette formule \u00e0 partir de notre ensemble d'observation, donc \u00e0 partir de notre ensemble d'apprentissage."
        },
        {
            "start": 2594,
            "end": 2615,
            "text": "Typiquement, ce qu'on va chercher \u00e0 estimer, c'est les probabilit\u00e9s PR de CK, donc la probabilit\u00e9 a priori pour chaque classe, et la probabilit\u00e9, la loi conditionnelle de X \u00e0 la classe CK, donc P de X sachant CK."
        },
        {
            "start": 2615,
            "end": 2623,
            "text": "On a maintenant tout ce qu'il faut pour appliquer ces mod\u00e8les g\u00e9n\u00e9ratifs \u00e0 notre probl\u00e8me de cat\u00e9gorisation de documents."
        },
        {
            "start": 2623,
            "end": 2640,
            "text": "Je reviens sur l'hypoth\u00e8se dont j'ai d\u00e9j\u00e0 parl\u00e9, qui va consister \u00e0 consid\u00e9rer que chaque vecteur repr\u00e9sentatif d'un document D, c'est la r\u00e9alisation d'une variable al\u00e9atoire multidimensionnelle, qui va \u00eatre g\u00e9n\u00e9r\u00e9e par le m\u00e9lange de K densit\u00e9 de probabilit\u00e9, avec des proportions \u03c0K."
        },
        {
            "start": 2640,
            "end": 2643,
            "text": "K \u00e9tant le nombre de classes possibles."
        },
        {
            "start": 2643,
            "end": 2657,
            "text": "Avec ces propri\u00e9t\u00e9s-l\u00e0, la somme des \u03c0K pour l'ensemble des classes possibles, c'est 1, et \u03c0K, c'est sup\u00e9rieur ou \u00e9gal \u00e0 0."
        },
        {
            "start": 2657,
            "end": 2686,
            "text": "Chaque fonction de densit\u00e9, c'est une fonction param\u00e9trique qui mod\u00e9lise la distribution de probabilit\u00e9 conditionnelle de classe, associ\u00e9e \u00e0 une classe K qui appartient \u00e0 Y. Cette distribution de probabilit\u00e9 conditionnelle de classe, on va l'exprimer comme une fonction de densit\u00e9, donc une fonction param\u00e9trique avec des param\u00e8tres \u03b8K."
        },
        {
            "start": 2686,
            "end": 2692,
            "text": "Pour la classe K. La densit\u00e9 de m\u00e9lange, elle mod\u00e9lise quoi ?"
        },
        {
            "start": 2692,
            "end": 2698,
            "text": "Elle mod\u00e9lise finalement la g\u00e9n\u00e9ration de D par ses K densit\u00e9 de probabilit\u00e9."
        },
        {
            "start": 2698,
            "end": 2716,
            "text": "Le mod\u00e8le g\u00e9n\u00e9ratif de D \u00e9tant donn\u00e9 l'ensemble des param\u00e8tres, c'est une loi de m\u00e9lange, c'est la somme pour l'ensemble des classes possibles, de \u03c0K fois cette fonction de densit\u00e9 associ\u00e9e \u00e0 chaque classe."
        },
        {
            "start": 2716,
            "end": 2721,
            "text": "Exactement comme tout \u00e0 l'heure, la poire ou la p\u00eache finalement."
        },
        {
            "start": 2721,
            "end": 2723,
            "text": "Ici, les classes sont diff\u00e9rentes."
        },
        {
            "start": 2723,
            "end": 2731,
            "text": "Donc, Theta, c'est l'ensemble des proportions \u03c0K et tous les param\u00e8tres qui d\u00e9finissent les fonctions de densit\u00e9 fK."
        },
        {
            "start": 2731,
            "end": 2740,
            "text": "Donc, \u03b8, c'est l'ensemble des \u03c0K pour chacune des classes possibles et puis les param\u00e8tres des lois de densit\u00e9."
        },
        {
            "start": 2740,
            "end": 2751,
            "text": "Le but de l'apprentissage, \u00e7a va \u00eatre d'estimer cet ensemble de param\u00e8tres \u03b8 pour qu'au sens du maximum de vraisemblance, le mod\u00e8le de m\u00e9lange explique au mieux les exemples de la base d'entra\u00eenement."
        },
        {
            "start": 2751,
            "end": 2765,
            "text": "Apr\u00e8s cette estimation des param\u00e8tres, on va pouvoir classer un nouveau document des primes \u00e0 une classe de l'ensemble Y en utilisant la r\u00e8gle de d\u00e9cision Bayesian que j'ai pr\u00e9sent\u00e9e tout \u00e0 l'heure."
        },
        {
            "start": 2765,
            "end": 2779,
            "text": "Des primes va appartenir \u00e0 la classe classe, 6K, c'est la remax pour l'ensemble des classes possibles, de P, de Y et de H, sachant des primes."
        },
        {
            "start": 2779,
            "end": 2792,
            "text": "Avec Bayes, toute cette \u00e9quation, je peux l'\u00e9crire comme \u00e7a, en faisant intervenir les param\u00e8tres de ma loi de m\u00e9lange, les param\u00e8tres de mon mod\u00e8le g\u00e9n\u00e9ratif."
        },
        {
            "start": 2792,
            "end": 2797,
            "text": "La vraie question, c'est comment estimer ces param\u00e8tres."
        },
        {
            "start": 2797,
            "end": 2818,
            "text": "Il y a deux mod\u00e8les qui vont faire des hypoth\u00e8ses sur notre repr\u00e9sentation du document qui vont nous permettre d'arriver \u00e0 une estimation possible de ces param\u00e8tres et donc \u00e0 des mod\u00e8les g\u00e9n\u00e9ratifs de cat\u00e9gorisation effectifs pour la cat\u00e9gorisation de documents."
        },
        {
            "start": 2818,
            "end": 2829,
            "text": "Un de ces premiers mod\u00e8les, c'est le mod\u00e8le multivari\u00e9 de Bernoulli qui va consid\u00e9rer que les documents sont ind\u00e9pendants et le mod\u00e8le multinomial."
        },
        {
            "start": 2829,
            "end": 2832,
            "text": "Commen\u00e7ons par le mod\u00e8le multivari\u00e9 de Bernoulli."
        },
        {
            "start": 2832,
            "end": 2842,
            "text": "Ce mod\u00e8le, ce n'est rien d'autre qu'une g\u00e9n\u00e9ralisation du mod\u00e8le probabiliste MIB que Myriam vous avait pr\u00e9sent\u00e9 lors du cours sur les mod\u00e8les probabilistes."
        },
        {
            "start": 2842,
            "end": 2855,
            "text": "L'hypoth\u00e8se de ce mod\u00e8le multivari\u00e9 de Bernoulli, c'est l'hypoth\u00e8se Na\u00efve Bayes qui dit que les termes qui apparaissent dans un document sont ind\u00e9pendants les uns des autres."
        },
        {
            "start": 2855,
            "end": 2879,
            "text": "Chaque document, on va le repr\u00e9senter comme un vecteur binaire d\u00e9fini sur l'espace des termes d'indexation, l'espace des termes de notre vocabulaire, construit sur notre collection, avec WID qui vaut 0 ou 1, selon que le terme est pr\u00e9sent ou non dans notre document."
        },
        {
            "start": 2879,
            "end": 2963,
            "text": "Si j'introduis cette repr\u00e9sentation vectorielle de D dans mes lois de densit\u00e9, F de k de D, \u03b8 k, va \u00eatre \u00e9gal \u00e0 la probabilit\u00e9 pour D qui est \u00e9gale \u00e0 sa repr\u00e9sentation sachant Y est \u00e9gale \u00e0 k. Comme j'ai fait l'hypoth\u00e8se que les termes \u00e9taient ind\u00e9pendants les uns des autres, \u00e7a va \u00eatre \u00e9gal au produit pour l'ensemble des termes de la probabilit\u00e9 de WID sachant que Y est \u00e9gale \u00e0 k. Si je pose quelques notations, et notamment je vais consid\u00e9rer que \u03b8 de TI sachant k, c'est la probabilit\u00e9 que le terme i soit pr\u00e9sent dans le document D, donc WID est \u00e9gal \u00e0 1 sachant Y est \u00e9gal \u00e0 k, c'est typiquement la probabilit\u00e9 de pr\u00e9sence du terme TI du vocabulaire dans la classe K, alors ma loi de densit\u00e9, je peux pour D, associer donc \u00e0 D pour la classe K, avec les param\u00e8tres \u03b8 k, je vais pouvoir l'\u00e9crire de cette mani\u00e8re."
        },
        {
            "start": 2963,
            "end": 2973,
            "text": "Donc c'est le produit pour chacun des termes de cette quantit\u00e9 l\u00e0."
        },
        {
            "start": 2973,
            "end": 2976,
            "text": "Voil\u00e0, \u00e7a c'est ce qu'on appelle une loi de Bernoulli."
        },
        {
            "start": 2976,
            "end": 2978,
            "text": "Alors pourquoi \u00e7a s'appelle une loi de Bernoulli ?"
        },
        {
            "start": 2978,
            "end": 2993,
            "text": "Parce que les \u00e9v\u00e9nements qui mod\u00e9lisent l'absence ou la pr\u00e9sence de termes du vocabulaire dans les diff\u00e9rentes classes, elles suivent ce qu'on appelle une loi de Bernoulli dont les param\u00e8tres sont propres \u00e0 chaque terme."
        },
        {
            "start": 2993,
            "end": 3003,
            "text": "Voil\u00e0, donc ici \u03b8 k, \u00e7a repr\u00e9sente l'ensemble des probabilit\u00e9s de pr\u00e9sence des termes du vocabulaire dans la KM classe ou dans la KM composante du m\u00e9lange."
        },
        {
            "start": 3003,
            "end": 3062,
            "text": "Et puis ce qu'on va chercher \u00e0 estimer, c'est ce grand \u03b8, donc cet ensemble de param\u00e8tres \u03b8 de k, c'est-\u00e0-dire pour chaque classe K, \u03c0k, et puis \u03b8 de ti sachant k. Cette estimation, on va pouvoir la faire au sens du maximum de vraisemblance des param\u00e8tres sur une base d'apprentissage C de taille M. Et en particulier, pour l'ensemble des termes de notre vocabulaire et pour l'ensemble des classes, \u03b8 de ti sachant k, on va pouvoir l'estimer comme \u00e9tant cette quantit\u00e9-l\u00e0, c'est-\u00e0-dire le df pour le terme i de la classe K sur nk de C. Et puis \u03c0k, on va pouvoir l'estimer comme \u00e9tant n de K sur C sur M. Alors, \u00e0 quoi correspondent ces diff\u00e9rentes quantit\u00e9s ?"
        },
        {
            "start": 3062,
            "end": 3080,
            "text": "n de K de C, c'est \u00e9gal au cardinal de SK, donc le cardinal de la classe SK, c'est l'ensemble des documents de la base d'apprentissage qui appartiennent \u00e0 la classe K. M, c'est le nombre total de documents dans notre base d'apprentissage."
        },
        {
            "start": 3080,
            "end": 3099,
            "text": "Et df de T de K, c'est le nombre de documents de la classe K qui contiennent au moins une fois le terme T. Donc \u00e7a, c'est l'estimation des param\u00e8tres de notre mod\u00e8le multivari\u00e9 de Bernoulli au sens du maximum de vraisemblance."
        },
        {
            "start": 3099,
            "end": 3111,
            "text": "En pratique, on ajoute \u00e0 ces estimations un lissage de la place et un passage au logarithme pour la r\u00e8gle de Bayes."
        },
        {
            "start": 3111,
            "end": 3123,
            "text": "Je vous ai mis sur les deux slides qui suivent les algorithmes qui correspondent \u00e0 la phase d'apprentissage et \u00e0 la phase de test, mais je vous laisserai regarder ces algorithmes \u00e0 t\u00eate repos\u00e9e."
        },
        {
            "start": 3123,
            "end": 3126,
            "text": "Je ne vais pas les d\u00e9tailler dans cette vid\u00e9o."
        },
        {
            "start": 3126,
            "end": 3128,
            "text": "Je vais acc\u00e9l\u00e9rer un peu."
        },
        {
            "start": 3128,
            "end": 3146,
            "text": "L'autre mod\u00e8le g\u00e9n\u00e9ratif qui est tr\u00e8s utilis\u00e9 en cat\u00e9gorisation pour la RI, c'est le mod\u00e8le multinomial, dans lequel on va consid\u00e9rer qu'un document D est repr\u00e9sent\u00e9 comme une s\u00e9quence ordonn\u00e9e de termes D. L'ordre des termes est pris en compte."
        },
        {
            "start": 3146,
            "end": 3151,
            "text": "La repr\u00e9sentation d'un document D, c'est une s\u00e9quence ordonn\u00e9e."
        },
        {
            "start": 3151,
            "end": 3156,
            "text": "Et cette s\u00e9quence ordonn\u00e9e est g\u00e9n\u00e9r\u00e9e \u00e0 partir d'un vocabulaire V donn\u00e9."
        },
        {
            "start": 3156,
            "end": 3173,
            "text": "On a toujours l'hypoth\u00e8se Na\u00efve-Bayes qui dit cette fois-ci que la probabilit\u00e9 de g\u00e9n\u00e9ration d'un terme par une composante du m\u00e9lange, par une classe, est ind\u00e9pendante du contexte et de la position de ce terme dans le document."
        },
        {
            "start": 3173,
            "end": 3186,
            "text": "Comme pour le mod\u00e8le de Bernoulli, on va inclure cette repr\u00e9sentation D sous la forme d'une s\u00e9quence ordonn\u00e9e de termes dans notre loi de densit\u00e9."
        },
        {
            "start": 3186,
            "end": 3217,
            "text": "En utilisant l'hypoth\u00e8se de Bayes, cette loi de densit\u00e9 associ\u00e9e \u00e0 la classe K, va \u00eatre \u00e9gale au produit pour l'ensemble des termes qui appartiennent \u00e0 un document de \u03b8 de TH, avec le \u03b8 de TH, qui est la probabilit\u00e9 de g\u00e9n\u00e9ration du terme TH par la Km composante du m\u00e9lange, par la Km classe."
        },
        {
            "start": 3217,
            "end": 3231,
            "text": "Ce qu'introduit ce mod\u00e8le multinomial par rapport au mod\u00e8le de Bernoulli, au mod\u00e8le pr\u00e9c\u00e9dent, c'est qu'il va capturer l'information de fr\u00e9quence des termes dans les documents, et plus seulement l'information de pr\u00e9sence-absence."
        },
        {
            "start": 3231,
            "end": 3246,
            "text": "On a vu plusieurs fois, notamment quand on a introduit le mod\u00e8le vectorial, que prendre en compte cette fr\u00e9quence des termes, \u00e7a avait un int\u00e9r\u00eat et \u00e7a a un impact sur les r\u00e9sultats."
        },
        {
            "start": 3246,
            "end": 3254,
            "text": "Comme pour le mod\u00e8le pr\u00e9c\u00e9dent, il faut estimer les param\u00e8tres."
        },
        {
            "start": 3254,
            "end": 3261,
            "text": "Il y a une erreur d'ailleurs ici, c'est le mod\u00e8le multinomial, je suis d\u00e9sol\u00e9e, je viens de m'en rendre compte."
        },
        {
            "start": 3261,
            "end": 3272,
            "text": "On estime ces param\u00e8tres au sens du maximum de vraisemblance sur une base d'apprentissage C de taille M, en introduisant un lissage de la place."
        },
        {
            "start": 3272,
            "end": 3288,
            "text": "Au sens du maximum de vraisemblance, on peut estimer les diff\u00e9rents param\u00e8tres de notre mod\u00e8le g\u00e9n\u00e9ratif, de cette mani\u00e8re-l\u00e0, o\u00f9 on voit qu'on a pris en compte la fr\u00e9quence des termes dans les documents."
        },
        {
            "start": 3288,
            "end": 3322,
            "text": "On a toujours ici un NK2C1 qui est le cardinal de la classe K dans notre ensemble d'apprentissage, et puis ici un TF2TID, c'est le nombre d'occurrences du terme TI dans le document D. S2K, c'est l'ensemble des documents de notre ensemble d'apprentissage qui appartiennent \u00e0 la classe K. Voil\u00e0, donc \u00e0 nouveau, je vous ai mis le d\u00e9tail des algorithmes pour la phase d'apprentissage et pour la phase de test, mais que je ne d\u00e9taillerai pas ici."
        },
        {
            "start": 3322,
            "end": 3339,
            "text": "On peut bien s\u00fbr aussi utiliser des mod\u00e8les discriminants, qui eux vont consister \u00e0 directement trouver une fonction F de classification, sans faire finalement d'hypoth\u00e8se sur la mani\u00e8re dont sont g\u00e9n\u00e9r\u00e9s les exemples."
        },
        {
            "start": 3339,
            "end": 3347,
            "text": "L\u00e0, on va retomber sur des choses que j'ai introduites tout \u00e0 l'heure sur l'apprentissage supervis\u00e9."
        },
        {
            "start": 3347,
            "end": 3368,
            "text": "Le classifieur recherch\u00e9 est suppos\u00e9 appartenir \u00e0 une classe de fonctions donn\u00e9es F, donc ma classe d'hypoth\u00e8se, et la forme analytique de cette fonction F, je vais la trouver en minimisant une fonction d'erreur, notre fonction de co\u00fbt d\u00e9finie tout \u00e0 l'heure."
        },
        {
            "start": 3368,
            "end": 3390,
            "text": "Tr\u00e8s souvent, comme on est dans un probl\u00e8me de classification, ici on utilise le co\u00fbt 0,1, o\u00f9 je vais compter le nombre de fausses pr\u00e9dictions, je vais p\u00e9naliser le nombre de fausses pr\u00e9dictions de ma fonction F. Un mod\u00e8le discriminant tr\u00e8s connu, ce sont les s\u00e9parateurs \u00e0 vaste marge lin\u00e9aire."
        },
        {
            "start": 3390,
            "end": 3418,
            "text": "L'objectif, c'est \u00e9tant donn\u00e9 nos donn\u00e9es d'apprentissage, qui sont \u00e9tiquet\u00e9es de mani\u00e8re binaire selon deux classes, moins 1 ou plus 1, on va chercher \u00e0 construire \u00e0 partir de cet ensemble d'apprentissage, une fonction F de d\u00e9cision qui va permettre de pr\u00e9dire la classe moins 1 ou plus 1 d'un point quelconque X appartenant \u00e0 notre ensemble d'entr\u00e9es grand X."
        },
        {
            "start": 3418,
            "end": 3427,
            "text": "La fonction de d\u00e9cision, je veux que ce soit une fonction de d\u00e9cision lin\u00e9aire."
        },
        {
            "start": 3427,
            "end": 3436,
            "text": "Voil\u00e0, donc \u00e7a c'est la forme analytique de cette fonction de d\u00e9cision lin\u00e9aire."
        },
        {
            "start": 3436,
            "end": 3451,
            "text": "Et puis l'apprentissage, \u00e7a va consister \u00e0 apprendre les param\u00e8tres W, J et B de cette fonction F, tel que je vais minimiser mon risque empirique."
        },
        {
            "start": 3451,
            "end": 3461,
            "text": "Je ne vais pas plus rentrer dans les d\u00e9tails de ces SVM, parce que je d\u00e9taillerai \u00e7a un peu plus pr\u00e9cis\u00e9ment lors de la prochaine s\u00e9ance."
        },
        {
            "start": 3461,
            "end": 3477,
            "text": "On va maintenant passer au dernier gros morceau du cours d'aujourd'hui, qui concerne l'apprentissage pour la RIE et l'ordonnancement."
        },
        {
            "start": 3477,
            "end": 3487,
            "text": "L'id\u00e9e, \u00e7a va \u00eatre de mod\u00e9liser la recherche d'informations comme un probl\u00e8me de cat\u00e9gorisation, pour se ramener \u00e0 un probl\u00e8me d'apprentissage."
        },
        {
            "start": 3487,
            "end": 3492,
            "text": "L'id\u00e9e g\u00e9n\u00e9rale, \u00e7a va \u00eatre de choisir une repr\u00e9sentation des exemples."
        },
        {
            "start": 3492,
            "end": 3500,
            "text": "Encore faut-il dire quels sont les exemples qu'on va consid\u00e9rer dans ce cadre-l\u00e0."
        },
        {
            "start": 3500,
            "end": 3509,
            "text": "Il va aussi falloir dire \u00e0 quoi correspondent les classes de sortie et quels sont leurs nombres."
        },
        {
            "start": 3509,
            "end": 3518,
            "text": "Une fois qu'on a un peu d\u00e9fini ces donn\u00e9es d'entr\u00e9e, il faut choisir le principe d'apprentissage et l'algorithme associ\u00e9."
        },
        {
            "start": 3518,
            "end": 3524,
            "text": "Ou faire en sorte d'en tester plusieurs et de choisir celui qui est le plus optimal."
        },
        {
            "start": 3524,
            "end": 3531,
            "text": "Revenons \u00e0 notre probl\u00e9matique de recherche d'informations."
        },
        {
            "start": 3531,
            "end": 3541,
            "text": "J'ai des requ\u00eates, et je vais consid\u00e9rer que j'ai des requ\u00eates pour lesquelles je dispose de jugements de pertinence dans ces."
        },
        {
            "start": 3541,
            "end": 3550,
            "text": "Typiquement, j'ai une requ\u00eate Q1 et un ensemble de documents avec leurs jugements de pertinence."
        },
        {
            "start": 3550,
            "end": 3555,
            "text": "En bleu, c'est les documents pertinents, en orange, c'est les documents non pertinents pour la requ\u00eate Q1."
        },
        {
            "start": 3555,
            "end": 3561,
            "text": "Et puis j'ai la m\u00eame chose pour une requ\u00eate Q2 et j'ai la m\u00eame chose pour une requ\u00eate Q3."
        },
        {
            "start": 3561,
            "end": 3579,
            "text": "Ces requ\u00eates pour lesquelles je dispose de jugements de pertinence, c'est \u00e7a qui va nous permettre de d\u00e9finir un ensemble d'apprentissages que je vais utiliser pour ensuite apprendre une fonction F, qui va \u00eatre utilis\u00e9e apr\u00e8s pour faire de la recherche d'informations."
        },
        {
            "start": 3579,
            "end": 3589,
            "text": "Les principaux verrous de l'apprentissage par ordonnancement, c'est de d\u00e9terminer quelles sont les donn\u00e9es qu'on va utiliser pour mettre en place l'apprentissage."
        },
        {
            "start": 3589,
            "end": 3598,
            "text": "La probl\u00e9matique de la notation des donn\u00e9es d'apprentissage, typiquement on voit bien qu'une sortie c'est mes jugements de pertinence, et donc quel jugement de pertinence je vais prendre en compte."
        },
        {
            "start": 3598,
            "end": 3600,
            "text": "Comment je d\u00e9cris mes donn\u00e9es ?"
        },
        {
            "start": 3600,
            "end": 3610,
            "text": "\u00c0 partir du moment o\u00f9 j'ai d\u00e9fini mes donn\u00e9es, qui sont des couples requ\u00eates documents, comment je les d\u00e9cris, donc quelles sont les caract\u00e9ristiques que je vais utiliser pour d\u00e9crire mes donn\u00e9es."
        },
        {
            "start": 3610,
            "end": 3619,
            "text": "Et puis bien s\u00fbr, apr\u00e8s, quel mod\u00e8le d'apprentissage j'utilise, quelle fonction de coup, quel algorithme, etc."
        },
        {
            "start": 3619,
            "end": 3625,
            "text": "Et puis apr\u00e8s, se pose aussi la question de comment j'\u00e9value cette fonction F que j'ai apprise \u00e0 partir des donn\u00e9es."
        },
        {
            "start": 3625,
            "end": 3628,
            "text": "Quelles sont les mesures que je vais pouvoir utiliser pour mon \u00e9valuation ?"
        },
        {
            "start": 3628,
            "end": 3634,
            "text": "La premi\u00e8re question, la question de comment je repr\u00e9sente mes donn\u00e9es, elle est fondamentale."
        },
        {
            "start": 3634,
            "end": 3639,
            "text": "C'est un probl\u00e8me crucial, qui est l'\u00e9tape qu'on appelle l'\u00e9tape de Feature Engineering."
        },
        {
            "start": 3639,
            "end": 3650,
            "text": "On a vu que les donn\u00e9es que je dois consid\u00e9rer pour faire de l'ordonnancement, ce ne sont pas les documents seuls, mais \u00e7a va \u00eatre des couples documents requ\u00eates."
        },
        {
            "start": 3650,
            "end": 3657,
            "text": "Et donc \u00e0 ce couple documents requ\u00eates, je vais pouvoir utiliser les donn\u00e9es que je vais utiliser pour faire de l'ordonnancement."
        },
        {
            "start": 3657,
            "end": 3665,
            "text": "Pour ce couple documents requ\u00eates, je vais devoir associer une repr\u00e9sentation standard X qui va \u00eatre d\u00e9finie dans RM, avec un M dimension."
        },
        {
            "start": 3665,
            "end": 3671,
            "text": "Les coordonn\u00e9es de X, je vais vouloir qu'elles soient tr\u00e8s g\u00e9n\u00e9rales."
        },
        {
            "start": 3671,
            "end": 3682,
            "text": "On va essayer de se reposer sur un maximum d'informations, et notamment, pourquoi pas, r\u00e9utiliser tout ce qu'on a introduit jusqu'\u00e0 maintenant dans le cours."
        },
        {
            "start": 3682,
            "end": 3700,
            "text": "Par exemple, je peux prendre comme premi\u00e8re dimension de mon vecteur X, la somme pour l'ensemble des termes qui appartiennent \u00e0 la fois au document et \u00e0 la requ\u00eate, du log de la fr\u00e9quence du terme dans le document."
        },
        {
            "start": 3700,
            "end": 3717,
            "text": "Comme deuxi\u00e8me composante, je peux par exemple prendre cette quantit\u00e9 l\u00e0, qui est pour l'ensemble des termes de la requ\u00eate, le log de 1 plus la fr\u00e9quence du terme dans le document sur le nombre de documents dans ma collection."
        },
        {
            "start": 3717,
            "end": 3739,
            "text": "Et puis voil\u00e0, je peux comme \u00e7a construire une repr\u00e9sentation X en prenant du coup un ensemble de mesures statistiques, de statistiques que je peux construire \u00e0 partir de ma requ\u00eate et de mon document."
        },
        {
            "start": 3739,
            "end": 3749,
            "text": "Je peux aussi par exemple prendre les scores qui me sont donn\u00e9s par d'autres mod\u00e8les, comme par exemple le mod\u00e8le vectoriel, le mod\u00e8le bool\u00e9en, le mod\u00e8le probabiliste, etc."
        },
        {
            "start": 3749,
            "end": 3762,
            "text": "L\u00e0, il n'y a rien qui est interdit il faut juste que j'associe \u00e0 ce couple QD un vecteur qui le caract\u00e9rise au mieux dans cette probl\u00e9matique de recherche d'informations."
        },
        {
            "start": 3762,
            "end": 3771,
            "text": "Voil\u00e0, donc \u00e7a c'est l'\u00e9tape fondamentale qui est l'\u00e9tape de Feature Engineering."
        },
        {
            "start": 3771,
            "end": 3796,
            "text": "Et donc \u00e0 une requ\u00eate et \u00e0 un ensemble de documents, donc je vais construire ce vecteur de caract\u00e9ristiques avec des choses, un ensemble de caract\u00e9ristiques qui sont d\u00e9pendantes du couple requ\u00eate-documents, mais aussi \u00e9ventuellement des caract\u00e9ristiques qui sont purement d\u00e9pendantes du document, par exemple on peut mettre le page rank, voire des caract\u00e9ristiques qui peuvent \u00eatre purement d\u00e9pendantes de la requ\u00eate, etc."
        },
        {
            "start": 3796,
            "end": 3804,
            "text": "Voil\u00e0, l'autre probl\u00e8me c'est finalement les valeurs de sortie, donc le choix du nombre de classes."
        },
        {
            "start": 3804,
            "end": 3810,
            "text": "Ce choix du nombre de classes, il d\u00e9pend a priori des valeurs de pertinence qu'on a \u00e0 notre disposition."
        },
        {
            "start": 3810,
            "end": 3816,
            "text": "Est-ce que j'ai des valeurs de pertinence binaires, est-ce que j'ai des valeurs de pertinence multivalu\u00e9es ou des scores de pertinence ?"
        },
        {
            "start": 3816,
            "end": 3823,
            "text": "Donc \u00e7a, on voit bien qu'il est assez facile d'avoir des valeurs de pertinence binaires."
        },
        {
            "start": 3823,
            "end": 3834,
            "text": "Si je veux des valeurs de pertinence multivalu\u00e9es ou des scores de pertinence, \u00e7a peut n\u00e9cessiter un travail d'annotation de longue haleine."
        },
        {
            "start": 3834,
            "end": 3841,
            "text": "Et puis bien s\u00fbr, c'est aussi tr\u00e8s d\u00e9pendant du syst\u00e8me en question et des pr\u00e9f\u00e9rences des concepteurs."
        },
        {
            "start": 3841,
            "end": 3851,
            "text": "Voil\u00e0, dans le cas le plus simple, j'ai deux classes, la classe des documents pertinents et la classe des documents non pertinents, et du coup je peux me ramener tr\u00e8s facilement \u00e0 un probl\u00e8me de cat\u00e9gorisation binaire."
        },
        {
            "start": 3851,
            "end": 3856,
            "text": "Voil\u00e0, alors j'ai d'autres possibilit\u00e9s."
        },
        {
            "start": 3856,
            "end": 3868,
            "text": "Si je dispose d'annotations du rang, donc avec des jugements binaires, donc documents pertinents ou non pertinents, je me ram\u00e8ne \u00e0 un probl\u00e8me de cat\u00e9gorisation binaire."
        },
        {
            "start": 3868,
            "end": 3883,
            "text": "Si j'ai des jugements multivalu\u00e9s, donc avec par exemple ce type de jugement, parfait, excellent, bon, meilleur, etc., des \u00e9chelles de graduation, je peux me ramener \u00e0 un probl\u00e8me de cat\u00e9gorisation multiclasse."
        },
        {
            "start": 3883,
            "end": 3889,
            "text": "Je peux aussi vouloir annoter des paires ordonn\u00e9es, et notamment, je peux avoir des paires de pr\u00e9f\u00e9rence."
        },
        {
            "start": 3889,
            "end": 3899,
            "text": "Donc typiquement, et \u00e7a c'est des choses qui sont assez faciles \u00e0 avoir dans le cadre du web, ces paires de pr\u00e9f\u00e9rence, en utilisant par exemple l'analyse des clics."
        },
        {
            "start": 3899,
            "end": 3909,
            "text": "Donc j'ai plut\u00f4t \u00e0 voir comme donn\u00e9e de sortie, en fait, le fait qu'un document D va \u00eatre plus pertinent qu'un autre document pour une requ\u00eate de donn\u00e9es."
        },
        {
            "start": 3909,
            "end": 3918,
            "text": "Voil\u00e0, donc \u00e7a c'est des choses qu'on peut tr\u00e8s facilement obtenir \u00e0 partir des informations de clics, \u00e0 partir du comportement utilisateur."
        },
        {
            "start": 3918,
            "end": 3928,
            "text": "Et puis, je peux avoir aussi des listes, avec donc des annotations de listes qui sont meilleures pour une requ\u00eate qu'une autre liste de documents."
        },
        {
            "start": 3928,
            "end": 3932,
            "text": "\u00c7a c'est des choses qui sont un peu plus difficiles \u00e0 mettre en \u0153uvre."
        },
        {
            "start": 3932,
            "end": 3952,
            "text": "Voil\u00e0, donc le choix du nombre de classes, vos valeurs de sortie, elles sont bien s\u00fbr tr\u00e8s d\u00e9pendantes du type d'annotation que vous pouvez associer \u00e0 vos donn\u00e9es, et notamment \u00e0 ces couples documents requ\u00eates."
        },
        {
            "start": 3952,
            "end": 3963,
            "text": "Voil\u00e0, alors apr\u00e8s la question du choix du principe d'apprentissage et de l'algorithme, typiquement elle est plus compliqu\u00e9e \u00e0 partir du moment o\u00f9 on a trait\u00e9 les deux pr\u00e9c\u00e9dentes questions."
        },
        {
            "start": 3963,
            "end": 3968,
            "text": "Donc apr\u00e8s la repr\u00e9sentation des donn\u00e9es, en fait, toutes les techniques de cat\u00e9gorisation peuvent \u00e0 priori \u00eatre utilis\u00e9es."
        },
        {
            "start": 3968,
            "end": 3973,
            "text": "Elles seront plus ou moins efficaces, mais elles peuvent \u00e0 priori toutes \u00eatre utilis\u00e9es."
        },
        {
            "start": 3973,
            "end": 3980,
            "text": "Voil\u00e0, donc on utilise beaucoup, ou on a beaucoup utilis\u00e9 les SVM parce qu'il y a une application assez directe."
        },
        {
            "start": 3980,
            "end": 3992,
            "text": "Typiquement, chaque couple QD contenant un document pertinent pour Q, elle va \u00eatre associ\u00e9e \u00e0 la classe plus 1, et les exemples avec les documents non pertinents \u00e0 la classe moins 1."
        },
        {
            "start": 3992,
            "end": 3999,
            "text": "On va donc apprendre un hyperplan s\u00e9parateur \u00e0 partir de cet ensemble d'apprentissage."
        },
        {
            "start": 3999,
            "end": 4007,
            "text": "Voil\u00e0, donc je vais chercher les param\u00e8tres avec la th\u00e9orie des SVM."
        },
        {
            "start": 4007,
            "end": 4016,
            "text": "Et puis, la valeur de sortie, elle me donnera directement une mesure pour d\u00e9finir un ordre sur les documents."
        },
        {
            "start": 4016,
            "end": 4026,
            "text": "Voil\u00e0, et donc le score d'un nouveau document pour une nouvelle requ\u00eate, il va \u00eatre directement fond\u00e9 sur les valeurs des fonctions de cat\u00e9gorisation associ\u00e9es."
        },
        {
            "start": 4026,
            "end": 4035,
            "text": "Voil\u00e0, alors apr\u00e8s, il y a trois grandes familles d'approches d'apprentissage pour l'ordonnancement."
        },
        {
            "start": 4035,
            "end": 4041,
            "text": "La premi\u00e8re famille d'approches, c'est l'approche qu'on appelle l'approche par points."
        },
        {
            "start": 4041,
            "end": 4045,
            "text": "En fait, les documents vont \u00eatre trait\u00e9s de mani\u00e8re ind\u00e9pendante dans cette approche."
        },
        {
            "start": 4045,
            "end": 4050,
            "text": "On ne va pas prendre en compte des pertes de pertinence, comme je l'ai expliqu\u00e9 tout \u00e0 l'heure."
        },
        {
            "start": 4050,
            "end": 4059,
            "text": "On va avoir donc des approches par paire, o\u00f9 l\u00e0 on va prendre en compte des pertes de pertinence, c'est l'approche perouaise, et on peut aussi avoir des approches par liste."
        },
        {
            "start": 4059,
            "end": 4069,
            "text": "Je vais me contenter pour la fin de ce cours de parler de l'approche par points et je reviendrai sur les approches par paire et par liste lors du prochain cours."
        },
        {
            "start": 4069,
            "end": 4081,
            "text": "Le principe de l'approche par points, c'est ce qu'on vient de voir, c'est-\u00e0-dire qu'on va formaliser le probl\u00e8me d'ordonnancement comme un probl\u00e8me de cat\u00e9gorisation ou de r\u00e9gression."
        },
        {
            "start": 4081,
            "end": 4086,
            "text": "Les documents, je les consid\u00e8re de mani\u00e8re ind\u00e9pendante en entr\u00e9e du syst\u00e8me d'apprentissage."
        },
        {
            "start": 4086,
            "end": 4105,
            "text": "Et puis, mon jugement de pertinence, \u00e7a peut \u00eatre soit un score r\u00e9el, auquel cas je vais me rapporter un probl\u00e8me de r\u00e9gression lin\u00e9aire, soit une classe de pertinence ordonn\u00e9e, auquel cas je peux me rapporter un probl\u00e8me de r\u00e9gression ordinal, soit j'ai une classe de pertinence non ordonn\u00e9e, et l\u00e0 je peux utiliser des techniques de classification."
        },
        {
            "start": 4105,
            "end": 4114,
            "text": "L'approche par points, on appelle \u00e7a une approche par points parce que mes documents sont consid\u00e9r\u00e9s de mani\u00e8re ind\u00e9pendante en entr\u00e9e du syst\u00e8me d'apprentissage."
        },
        {
            "start": 4114,
            "end": 4132,
            "text": "Si j'ai un score de pertinence r\u00e9el, je me ram\u00e8ne \u00e0 un probl\u00e8me de r\u00e9gression lin\u00e9aire et je vais r\u00e9soudre ce probl\u00e8me de r\u00e9gression en minimisant pour chaque document une fonction de perte, qui est par exemple la somme des diff\u00e9rences au carr\u00e9."
        },
        {
            "start": 4132,
            "end": 4142,
            "text": "Avec Y qui est le score de pertinence de r\u00e9f\u00e9rence pour un document DI et Y qui est le score de pertinence pr\u00e9dit."
        },
        {
            "start": 4142,
            "end": 4151,
            "text": "La fonction de perte, c'est la diff\u00e9rence au carr\u00e9, et puis du coup, mon risque empirique, \u00e7a va \u00eatre la somme des diff\u00e9rences au carr\u00e9."
        },
        {
            "start": 4151,
            "end": 4176,
            "text": "Si j'ai des classes de pertinence ordonn\u00e9e, et puis si j'ai des classes de pertinence ordonn\u00e9e, je vais avoir un probl\u00e8me de r\u00e9gression ordinale, qui va prendre en compte l'ordre relatif entre les classes, et du coup il va s'agir de d\u00e9terminer F qui est une fonction d'ordonnancement qui va retourner un score r\u00e9el de pertinence et N moins un seuil qui d\u00e9termine la r\u00e9gression ordinaire."
        },
        {
            "start": 4176,
            "end": 4192,
            "text": "Et puis, si j'ai des classes de pertinence ordonn\u00e9e, qui va retourner un score r\u00e9el de pertinence et N moins un seuil qui d\u00e9terminent finalement les limites des N cat\u00e9gories de pertinence."
        },
        {
            "start": 4192,
            "end": 4199,
            "text": "Voil\u00e0, concernant ce premier cours sur l'apprentissage pour l'ARI."
        },
        {
            "start": 4199,
            "end": 4213,
            "text": "En conclusion, ce que je vous ai pr\u00e9sent\u00e9 aujourd'hui, il y a une grosse partie qui \u00e9tait quand m\u00eame une partie de rappel sur l'apprentissage, mais sinon je vous ai pr\u00e9sent\u00e9 un nouveau paradigme pour l'ARI."
        },
        {
            "start": 4213,
            "end": 4222,
            "text": "J'ai d\u00e9taill\u00e9 \u00e0 la fin de ce cours l'approche par points, o\u00f9 le probl\u00e8me d'ordonnancement, on le transforme en un probl\u00e8me de cat\u00e9gorisation ou de r\u00e9gression."
        },
        {
            "start": 4222,
            "end": 4229,
            "text": "Ces approches d'apprentissage, il faut retenir que ce sont des approches qui vont tenter d'exploiter toutes les informations \u00e0 disposition."
        },
        {
            "start": 4229,
            "end": 4236,
            "text": "On a des r\u00e9sultats qui vont \u00eatre comparables \u00e0 ceux des mod\u00e8les probabilistes quand on a des collections qui sont classiques."
        },
        {
            "start": 4236,
            "end": 4246,
            "text": "Quand on a des grosses collections, et notamment par exemple dans le cas du web, pour lequel on peut disposer d'un espace d'attributs qui est tr\u00e8s riche, on va avoir des meilleurs r\u00e9sultats."
        },
        {
            "start": 4246,
            "end": 4261,
            "text": "Apr\u00e8s, il peut se poser des probl\u00e8mes de mal\u00e9diction de la dimension, et typiquement si notre description de notre couple requ\u00eate document est tr\u00e8s grand, on peut avoir apr\u00e8s des probl\u00e8mes de mal\u00e9diction de la dimension."
        },
        {
            "start": 4261,
            "end": 4266,
            "text": "On peut se poser des questions de r\u00e9duction de cette dimension pour \u00e9viter ces probl\u00e8mes."
        },
        {
            "start": 4266,
            "end": 4272,
            "text": "Il y a un probl\u00e8me qui est non n\u00e9gligeable, qui est la disponibilit\u00e9 des annotations."
        },
        {
            "start": 4272,
            "end": 4283,
            "text": "Comment je peux obtenir des jugements de pertinence, pour constituer un jeu de donn\u00e9es d'apprentissage, pour apr\u00e8s mettre en oeuvre toutes ces techniques d'apprentissage ?"
        },
        {
            "start": 4283,
            "end": 4290,
            "text": "Voil\u00e0 quelques petites lectures conseill\u00e9es pour compl\u00e9ter cette premi\u00e8re partie du cours."
        },
        {
            "start": 4290,
            "end": 4295,
            "text": "Je vous souhaite de bien mettre tout cela en application lors du Lab d'aujourd'hui."
        }
    ],
    "text": "Bonjour, nous entamons aujourd'hui la derni\u00e8re th\u00e9matique qui sera trait\u00e9e dans ce cours sp\u00e9cifique de la ST4 et qui traite de l'apprentissage pour la recherche d'informations. Ce sera un cours en deux parties, il y aura donc la suite de ce cours qui sera le sujet de la prochaine s\u00e9ance. Rapidement, pour introduire ce nouveau paradigme pour la recherche d'informations, je vais d'abord revenir sur les syst\u00e8mes de recherche d'informations classiques que nous avons vus jusqu'alors. Ce que nous avons vu jusqu'alors, c'est que pour une requ\u00eate de N\u00e9Q qui traduit un besoin d'information, une collection de documents qui est index\u00e9e, on a vu un certain nombre de mod\u00e8les de recherche qui permettent de retourner une liste ordonn\u00e9e de documents. Ces mod\u00e8les de recherche peuvent \u00eatre divers, nous en avons vu plusieurs lors de ce cours. Par exemple, ici, ce mod\u00e8le de recherche pourrait \u00eatre la probabilit\u00e9 de pertinence sachant Q et D et qui pourrait \u00eatre estim\u00e9e en utilisant par exemple le mod\u00e8le BM25 qui est fonction de l'IDF et puis d'une fonction de pond\u00e9ration portant sur la fr\u00e9quence des termes dans un document et puis une normalisation par la longueur du document. Tout au long du cours, on a vu plusieurs types de mod\u00e8les, des mod\u00e8les bas\u00e9s similarit\u00e9s comme le mod\u00e8le bool\u00e9en ou le mod\u00e8le vectoriel. On a aussi pr\u00e9sent\u00e9 plusieurs mod\u00e8les probabilistes, notamment le mod\u00e8le d'ind\u00e9pendance binaire et le mod\u00e8le BM25. Et puis, plus derni\u00e8rement, on a pr\u00e9sent\u00e9 des mod\u00e8les qui prennent en compte la structure de la collection et notamment tous les mod\u00e8les qui sont bas\u00e9s sur une analyse des liens de la collection, comme par exemple le mod\u00e8le du page rank ou le mod\u00e8le head. Quelques discussions sur ces mod\u00e8les de classement. Pour un mod\u00e8le particulier, on a vu que le param\u00e9trage est souvent difficile, surtout quand il y a beaucoup de param\u00e8tres. Typiquement, pour le mod\u00e8le vectoriel, quelle est la bonne mesure de pond\u00e9ration \u00e0 utiliser pour le document pour la requ\u00eate, quelle est la bonne distance \u00e0 utiliser, etc. Pour comparer deux mod\u00e8les, on a vu aussi que c'\u00e9tait compliqu\u00e9. \u00c7a, c'est notamment tout le cours qui a trait \u00e0 l'\u00e9valuation. La comparaison rigoureuse, c'est quelque chose qui est assez difficile et notamment en recherche d'informations, on met plut\u00f4t en \u0153uvre des \u00e9valuations par benchmark, donc une \u00e9valuation empirique. On peut souvent \u00eatre dans des probl\u00e9matiques o\u00f9 on est dans des cas de surparam\u00e9trage. Et puis, si cette fois-ci on prend une collection de mod\u00e8les, par exemple l'ensemble des mod\u00e8les probabilistes versus l'ensemble des mod\u00e8les par similarit\u00e9, \u00e7a se complexifie. On a notamment beaucoup de mod\u00e8les qui existent. Dans la litt\u00e9rature, on en d\u00e9nombre plus d'une centaine, voire maintenant m\u00eame des milliers. Et il y a plusieurs questions qui peuvent se poser, notamment quel est le meilleur des mod\u00e8les ? Comment je peux comparer ces mod\u00e8les et \u00e9ventuellement comment je peux les combiner ? Les syst\u00e8mes actuels, notamment les syst\u00e8mes de recherche web que vous utilisez quotidiennement, pour une requ\u00eate donn\u00e9e, ils calculent souvent plusieurs centaines de fonctions de score de base. Entre cette requ\u00eate et chaque document de la collection, et ils combinent ces scores. Donc une question cl\u00e9, c'est comment combiner ces scores ? Et notamment, \u00e7a c'est toute la science qu'on appelle la science des CEO. Avec typiquement, vous pourrez trouver un ensemble d'articles assez g\u00e9n\u00e9ralistes qui justement parlent des 200 facteurs de classement de Google et qui donnent des recommandations, notamment si vous voulez que votre site web soit bien r\u00e9f\u00e9renc\u00e9. Il y a un paquet d'illustrations assez rigolotes d'ailleurs sur ces facteurs et param\u00e8tres. Alors voil\u00e0, notamment une illustration sous la forme d'une table p\u00e9riodique, justement des facteurs de succ\u00e8s des SEO, notamment pour tout ce qui est r\u00e9f\u00e9rencement de site web. Avec donc des facteurs qui sont propres \u00e0 la page, des facteurs qui sont ext\u00e9rieurs, contextuels, etc. Il y a toute une litt\u00e9rature sur ce sujet l\u00e0. Voil\u00e0, et c'est l\u00e0 qu'intervient l'apprentissage pour la recherche d'informations, parce qu'en fait les techniques d'apprentissage automatique, c'est des bons outils pour le param\u00e9trage automatique, pour combiner plusieurs \u00e9vidences, donc la question de la combinaison et de la fusion des scores dont on parlait juste avant, et puis ils permettent aussi d'\u00e9viter le surparam\u00e9trage. Donc toutes ces approches d'apprentissage pour la RI, elles ont un nom, c'est ce qu'on appelle le Learning to Rank, et \u00e7a rassemble l'ensemble des m\u00e9thodes qui vont utiliser des approches d'apprentissage pour le probl\u00e8me de l'ordonnancement. C'est la science qu'on appelle la science d'apprendre \u00e0 ordonner, et qui a explos\u00e9 dans le domaine de la recherche d'informations \u00e0 partir de 2005. Tous les moteurs de recherche actuels utilisent des approches \u00e0 base d'apprentissage, et m\u00eame aujourd'hui \u00e0 base d'apprentissage profond. Notamment, ce dont on va parler aujourd'hui, c'est l'optimisation automatique \u00e0 l'aide d'algorithmes d'apprentissage de la fonction d'ordonnancement. Et donc on va introduire un nouveau mod\u00e8le pour la recherche d'informations qui va suivre ce sch\u00e9ma-l\u00e0. C'est-\u00e0-dire qu'on va consid\u00e9rer un ensemble de donn\u00e9es, qui vont \u00eatre nos donn\u00e9es d'apprentissage, qui sont compos\u00e9es de requ\u00eates et d'un ensemble de documents qui sont associ\u00e9s \u00e0 ces requ\u00eates, et bien s\u00fbr de jugements de pertinence entre cette requ\u00eate et ces documents. Donc \u00e7a on va le faire, on va prendre en compte des donn\u00e9es pour plusieurs requ\u00eates. Et puis sur cet ensemble de donn\u00e9es, qu'on va appeler l'ensemble d'apprentissage, on va utiliser un syst\u00e8me d'apprentissage qui va apprendre une fonction de classement F de QD. Et puis pour une nouvelle requ\u00eate, Q de M plus 1, et notre ensemble de documents, notre collection qui reste index\u00e9e, avec l'ensemble des principes d'indexation qu'on a vus jusqu'alors, et bien on va appliquer ce mod\u00e8le appris, ce syst\u00e8me d'ordonnancement appris, pour classer les documents pertinents pour la requ\u00eate QI de M1, avec ce mod\u00e8le d'apprentissage. Donc on aura toujours en sortie une liste ordonn\u00e9e de documents. \u00c7a, \u00e7a ne change pas. Ce qui change, c'est vraiment ce syst\u00e8me d'apprentissage qui va utiliser des donn\u00e9es d'apprentissage pour apprendre cette fonction d'ordonnancement, qui elle ensuite est utilis\u00e9e de mani\u00e8re classique dans un syst\u00e8me d'ordonnancement. Donc l'apprentissage pour l'AERI, en fait, il va reposer sur deux concepts principaux, qui sont la notation des donn\u00e9es et la repr\u00e9sentation des couples requ\u00eates documents dans un espace de caract\u00e9ristiques qu'il faudra d\u00e9terminer. \u00c7a, c'est une \u00e9tape tr\u00e8s importante, qu'on appelle l'\u00e9tape de description ou feature engineering. Et puis, il y a la phase d'apprentissage en tant que telle, avec l'utilisation d'une structure d'apprentissage en deux \u00e9tapes assez classique, avec une \u00e9tape d'apprentissage de la fonction d'ordonnancement F de QD, et puis une \u00e9tape de test, d'utilisation du mod\u00e8le appris sur de nouvelles requ\u00eates. Voil\u00e0, donc au final, on a vraiment ce sch\u00e9ma-l\u00e0 pour la recherche d'informations avec apprentissage, donc pour le learning to rank, un ensemble de jeux de donn\u00e9es d'apprentissage qui sont compos\u00e9s de couples requ\u00eates documents qu'on va d\u00e9crire. Voil\u00e0, donc notamment, en fait, une grosse partie du travail, \u00e7a va \u00eatre de constituer ce vecteur X, qui est un vecteur caract\u00e9ristique de ce couple requ\u00eates documents. Ces donn\u00e9es, elles sont labellis\u00e9es, c'est-\u00e0-dire qu'on a une v\u00e9rit\u00e9 terrain, et cette v\u00e9rit\u00e9 terrain, en fait, elle est fonction de la pertinence du document D1 pour la requ\u00eate Q1. Et puis, donc, on a un syst\u00e8me d'apprentissage qui va reposer sur l'optimisation d'une fonction et d'un crit\u00e8re. On va donc, en sortie, avoir un mod\u00e8le F qui est appris \u00e0 partir de ces donn\u00e9es d'apprentissage. Et puis, donc, on a nos nouvelles donn\u00e9es qui sont nos donn\u00e9es de test ou nos donn\u00e9es de production o\u00f9, cette fois-ci, on n'a pas la v\u00e9rit\u00e9 terrain, donc on n'a pas les valeurs de pertinence, et l'objectif, \u00e7a va \u00eatre justement de pr\u00e9dire ces valeurs avec le mod\u00e8le appris. Donc, on va d\u00e9crire de la m\u00eame mani\u00e8re le couple Q1 D1, et puis, en fait, ce que va retourner le syst\u00e8me d'ordonnancement, c'est une liste ordonn\u00e9e des documents, donc selon cette fonction d'ordonnancement. On va donc d\u00e9tailler tous ces concepts lors de ce cours, et je vais d'abord vous rappeler quelques g\u00e9n\u00e9ralit\u00e9s sur l'apprentissage, et notamment l'apprentissage supervis\u00e9. Puis, on parlera du cas sp\u00e9cifique de la cat\u00e9gorisation de documents appliqu\u00e9s \u00e0 la recherche d'informations. On parlera donc de la recherche d'informations et de l'ordonnancement. Et puis, la semaine prochaine, on parlera plus sp\u00e9cifiquement, donc on continuera \u00e0 la partie arri\u00e8re d'ordonnancement, et on parlera aussi plus sp\u00e9cifiquement des donn\u00e9es d'apprentissage \u00e0 utiliser ou \u00e0 constituer, et des diff\u00e9rents jeux de tests qui sont \u00e0 disposition de la communaut\u00e9. Donc, pour commencer, quelques g\u00e9n\u00e9ralit\u00e9s sur l'apprentissage. On va consid\u00e9rer un processus d'inf\u00e9rence en trois \u00e9tapes, o\u00f9 la premi\u00e8re \u00e9tape va \u00eatre d'observer un ph\u00e9nom\u00e8ne, puis \u00e0 partir de cette observation du ph\u00e9nom\u00e8ne, \u00e0 partir de donn\u00e9es d'observation de ce ph\u00e9nom\u00e8ne, on va construire un mod\u00e8le associ\u00e9 \u00e0 ce ph\u00e9nom\u00e8ne. Et puis, l'id\u00e9e, c'est ensuite d'utiliser ce mod\u00e8le pour faire des pr\u00e9dictions relatives justement \u00e0 ce ph\u00e9nom\u00e8ne. L'apprentissage automatique, c'est l'automatisation de ce processus d'inf\u00e9rence. Avec une hypoth\u00e8se forte qui dit qu'il existe des relations entre les donn\u00e9es et que les algorithmes d'apprentissage vont nous permettre de les trouver. Il existe diff\u00e9rentes familles d'algorithmes d'apprentissage, et classiquement, on les cat\u00e9gorise selon deux grands axes. Le premier axe, c'est le mode d'apprentissage, avec diff\u00e9rents modes d'apprentissage assez connus. Notamment l'apprentissage supervis\u00e9, pour lequel on va vouloir apprendre des relations entre des entr\u00e9es et des sorties, avec un oracle qui nous donne des exemples qui vont exprimer ces relations. On va avoir \u00e0 disposition ce qu'on va appeler un ensemble d'apprentissage, avec des donn\u00e9es d'entr\u00e9e qui vont \u00eatre labellis\u00e9es. L'autre mode d'apprentissage, c'est l'apprentissage non supervis\u00e9. Cette fois-ci, on n'a pas d'oracle, donc on n'a pas d'exemple qui exprime des relations entre des entr\u00e9es et des sorties. Ce qu'on va chercher \u00e0 faire, c'est apprendre une structure dans un ensemble de donn\u00e9es. Typiquement, ces techniques d'apprentissage non supervis\u00e9, c'est toutes les techniques qu'on appelle les techniques de clustering. Et puis, on a d'autres paradigmes, comme par exemple l'apprentissage semi-supervis\u00e9, o\u00f9 l'objectif, c'est toujours bien d'apprendre les relations entre des entr\u00e9es et des sorties. Parmi les exemples \u00e0 notre disposition, l'oracle nous fournit la sortie seulement pour un petit nombre de ces exemples. L'id\u00e9e de l'apprentissage semi-supervis\u00e9, \u00e7a va \u00eatre de tirer parti de ces exemples, et l'id\u00e9e de l'apprentissage semi-supervis\u00e9, \u00e7a va \u00eatre de tirer parti des autres donn\u00e9es, c'est-\u00e0-dire des donn\u00e9es sans \u00e9tiquettes. C'est un mode d'apprentissage qui revient beaucoup au go\u00fbt du jour, notamment \u00e0 cause du succ\u00e8s des techniques d'apprentissage profond, qui n\u00e9cessitent lors de la phase d'apprentissage d'\u00e9norm\u00e9ment de donn\u00e9es supervis\u00e9es, donc de donn\u00e9es annot\u00e9es, qui sont co\u00fbteuses \u00e0 obtenir \u00e0 grande \u00e9chelle. Les donn\u00e9es sans annotation sont moins co\u00fbteuses \u00e0 obtenir, et l'id\u00e9e du semi-supervis\u00e9, c'est aussi de tirer parti de ces donn\u00e9es qui sont plus faciles \u00e0 obtenir. On peut aussi classer les techniques d'apprentissage selon le type de probl\u00e8me qu'on souhaite traiter. Typiquement, pour les algorithmes d'apprentissage supervis\u00e9, on a souvent deux grands types de probl\u00e8mes, le probl\u00e8me qu'on appelle la r\u00e9gression et la classification. Ce qui diff\u00e9rencie ces probl\u00e8mes, c'est le type des valeurs de sortie. Typiquement, pour la r\u00e9gression, on va chercher \u00e0 pr\u00e9dire une valeur continue, et pour la classification, on va chercher \u00e0 pr\u00e9dire une valeur dans un ensemble discret, dans un ensemble de classes discr\u00e8tes. On a aussi beaucoup d'autres approches, beaucoup d'autres familles d'apprentissage, notamment l'apprentissage par renforcement, qui est connu, parce que c'est notamment le type d'apprentissage qui a \u00e9t\u00e9 mis en oeuvre en partie dans AlphaGo, qui a vaincu l'Is\u00e9dol au jeu de Go, et qui consiste \u00e0 apprendre un comportement face \u00e0 diverses situations, en optimisant une r\u00e9compense quantitative. On a aussi l'apprentissage actif, o\u00f9 on va demander \u00e0 un utilisateur ou un p\u00f4le d'utilisateurs d'annoter un sous-ensemble de donn\u00e9es de mani\u00e8re incr\u00e9mentale. Et puis prendre en compte ce sous-ensemble de donn\u00e9es \u00e0 noter au fur et \u00e0 mesure pour am\u00e9liorer notre mod\u00e8le. Et puis il y a d'autres modes d'apprentissage, comme l'apprentissage par analogie, le m\u00e9ta-apprentissage, etc. Dans ce cours, on va principalement se r\u00e9f\u00e9rer \u00e0 l'apprentissage supervis\u00e9. Je vais d\u00e9j\u00e0 commencer par rappeler quelques principes de l'apprentissage supervis\u00e9. On va consid\u00e9rer un espace d'entr\u00e9e X qui est inclus dans Rd, et un espace de sortie Y qui est inclus dans R. On peut par exemple vouloir pr\u00e9dire une valeur dans R, ou on va pouvoir aussi vouloir pr\u00e9dire des cat\u00e9gories. La r\u00e9gression pr\u00e9dit une valeur dans R, ou cat\u00e9gorie, donc \u00e7a va \u00eatre des choses discr\u00e8tes. L'hypoth\u00e8se fondamentale de l'apprentissage supervis\u00e9, c'est cette hypoth\u00e8se-l\u00e0, qui dit que les paires d'exemples XY sont IID, c'est-\u00e0-dire qu'elles sont identiquement et ind\u00e9pendamment distribu\u00e9es suivant une distribution de probabilit\u00e9 fixe, mais qui est inconnue, D. Ce qu'on a \u00e0 disposition, c'est un ensemble d'\u00e9chantillons, c'est-\u00e0-dire une s\u00e9quence de n paires XY qui sont donc bien s\u00fbr g\u00e9n\u00e9r\u00e9es suivant cette distribution de probabilit\u00e9 fixe, mais inconnue, D. Cet ensemble de couples, de paires XY, c'est ce qu'on appelle l'ensemble d'apprentissage. Le but de l'apprentissage supervis\u00e9, \u00e7a va \u00eatre de construire une fonction F qui va de X dans Y et qui va pr\u00e9dire la sortie Y d'une nouvelle observation X avec une probabilit\u00e9 d'erreur minimale. La plupart des techniques d'apprentissage supervis\u00e9 reposent sur des travaux th\u00e9oriques, notamment qu'on doit \u00e0 Vladimir Vapnik et ses coll\u00e8gues, et qui a montr\u00e9 qu'on pouvait borner la probabilit\u00e9 d'erreur, donc cette probabilit\u00e9 d'erreur qu'on veut minimale, RF, qui est le risque fonctionnel, je reviendrai sur cette notion juste un peu plus tard, par l'erreur empirique de F, l'erreur qu'on va pouvoir mesurer sur l'ensemble d'apprentissage, plus deux termes qui sont fonction de la complexit\u00e9 de la classe de fonctions, donc la classe de fonctions F qu'on va choisir. Par exemple, on pourrait prendre la classe des fonctions lin\u00e9aires ou d'autres classes de fonctions, plus un terme r\u00e9siduel. Donc la question fondamentale de l'apprentissage supervis\u00e9, c'est comment choisir F ? Juste quelques remarques importantes sur l'apprentissage supervis\u00e9, des choses \u00e0 retenir. La seule observation dont on dispose, c'est l'ensemble des couples XY, c'est notre \u00e9chantillon, notre ensemble d'apprentissage D est inconnu. Je viens de le dire, cet \u00e9chantillon, cet ensemble C, c'est ce qu'on appelle l'ensemble d'apprentissage. Donc X, \u00e7a appartient \u00e0 grand X, et en g\u00e9n\u00e9ral, on prend une repr\u00e9sentation vectoriale, donc X est inclus dans grand Rd. Dans notre cas, X, \u00e7a va consister en un document, et on va repr\u00e9senter ce document par un vecteur dans l'espace vectorial des termes, en utilisant la repr\u00e9sentation sac de mots qu'on a introduit plus t\u00f4t dans le cours. Y, \u00e7a appartient \u00e0 Y, et par exemple, si on a un probl\u00e8me de cat\u00e9gorisation binaire, on consid\u00e8re souvent que Y, c'est moins un ou plus un. Dans notre cas, c'est assez facile de se ramener \u00e0 un probl\u00e8me de cat\u00e9gorisation binaire. Typiquement, on peut vouloir classer les documents en documents pertinents versus documents non pertinents. On classe la classe des documents pertinents versus la classe des documents non pertinents. Revenons \u00e0 l'objectif de l'apprentissage supervis\u00e9. On l'a dit tout \u00e0 l'heure, on cherche \u00e0 construire une fonction F \u00e0 partir des n donn\u00e9es d'apprentissage, telle que F va pr\u00e9dire la sortie Y associ\u00e9e \u00e0 une donn\u00e9e X. Quelles sont les propri\u00e9t\u00e9s voulues de F ? Quelles sont les propri\u00e9t\u00e9s de cette fonction F ? La premi\u00e8re propri\u00e9t\u00e9 relativement intuitive, c'est bien s\u00fbr que F doit pr\u00e9dire les bonnes valeurs pour l'ensemble des donn\u00e9es de notre ensemble d'apprentissage. Quelles que soient XI et Y dans C, F de XI doit \u00eatre \u00e9gal \u00e0 Y. L'autre propri\u00e9t\u00e9 fondamentale en apprentissage automatique, c'est que F doit aussi pouvoir pr\u00e9dire les bonnes sorties pour des exemples futurs XJ, c'est-\u00e0-dire pour des donn\u00e9es X qui n'appartiennent pas \u00e0 l'ensemble d'apprentissage. C'est ce qu'on conna\u00eet sous le probl\u00e8me de la g\u00e9n\u00e9ration de donn\u00e9es. Juste quelques illustrations, et notamment selon l'axe type de probl\u00e8me \u00e0 traiter. Si Y est \u00e0 valeur r\u00e9elle, c'est-\u00e0-dire que Y est \u00e9gal \u00e0 Rm, alors on est dans ce cas-l\u00e0, on est dans un cas de r\u00e9gr\u00e9gation de la valeur de la donn\u00e9e. On a donc un X qui est \u00e9gal \u00e0 Rm, et on a un X qui est \u00e9gal \u00e0 Rm. On est dans un cas de r\u00e9gression. Ici, on a une illustration d'un probl\u00e8me de r\u00e9gression. On a les points noirs qui sont nos donn\u00e9es d'apprentissage, on a la vraie fonction, et ce qu'on cherche \u00e0 construire, c'est une fonction F de X qui va \u00eatre la plus proche possible de la fonction en bleu. Qui va \u00eatre une bonne estimation de cette fonction en bleu qui repr\u00e9sente la vraie fonction. Quand on est sur un probl\u00e8me de classification, XI va \u00eatre associ\u00e9 \u00e0 une sortie cat\u00e9goriale. On voit ici une illustration d'un probl\u00e8me o\u00f9 on a deux classes. Un probl\u00e8me de classification binaire, les points noirs et les points rouges. Ici, on est sur un probl\u00e8me de classification \u00e0 trois classes. On voit bien les classes qui sont bien s\u00e9par\u00e9es. Dans ce cas-l\u00e0, on va parler de classification. Supposons qu'on a notre fonction F On peut se poser des questions sur la qualit\u00e9 de cette fonction F Pour \u00e7a, on va s'\u00e9quiper d'une fonction de co\u00fbt, qu'on appelle la fonction de co\u00fbt aussi la loss function et donc qui est un \u00e9l\u00e9ment cl\u00e9 de la th\u00e9orie de l'apprentissage, de comment fonctionne l'apprentissage supervis\u00e9. Et notamment cette fonction de coup, elle doit permettre de p\u00e9naliser les erreurs. Typiquement, cette fonction de coup, elle doit p\u00e9naliser le cas o\u00f9 on va avoir une pr\u00e9diction Y, chapeau, donc Y chapeau qui est \u00e9gale \u00e0 f de X, qui est diff\u00e9rente du vrai Y que l'on conna\u00eet, donc dans les donn\u00e9es qu'on a dans notre ensemble d'apprentissage. Voil\u00e0 donc une fonction de coup, c'est une fonction L qui va de Y dans R plus, telle que L de Y qui va \u00eatre sup\u00e9r\u00e9e \u00e0 z\u00e9ro pour toute Y qui est diff\u00e9rente de Y. Donc ce qu'on veut au travers de cette fonction de coup, bien s\u00fbr, c'est que le co\u00fbt d'une bonne pr\u00e9diction soit plus faible que le co\u00fbt d'une erreur. Alors il existe \u00e9norm\u00e9ment de fonctions de coup possibles. Si par exemple on se rapporte \u00e0 un probl\u00e8me de classification, on a un co\u00fbt qui est tr\u00e8s connu, qui est le co\u00fbt 0,1, o\u00f9 on va avoir un co\u00fbt de z\u00e9ro si Y est \u00e9gal \u00e0 f de X, donc si Y est \u00e9gal \u00e0 f de X, c'est-\u00e0-dire si on a une bonne pr\u00e9diction et un sinon. Typiquement, ce co\u00fbt 0,1, il consiste \u00e0 mesurer le nombre de points qui est mal class\u00e9 par la fonction f. Donc l\u00e0, \u00e7a devient int\u00e9ressant et on rentre un petit peu plus dans la th\u00e9orie de l'apprentissage supervis\u00e9, notamment en introduisant la minimisation du risque. Donc ce qu'on souhaite, c'est construire une fonction f \u00e0 partir de n donn\u00e9es, donc nos donn\u00e9es d'apprentissage, et ce qu'on veut c'est que f donne des bonnes approximations sur ces n donn\u00e9es et aussi sur les donn\u00e9es futures. Donc en fait, ce qu'on cherche \u00e0 faire, c'est minimiser le risque, ou risque fonctionnel ou erreur de g\u00e9n\u00e9ralisation, qui est finalement l'esp\u00e9rance de notre fonction de coup L, par rapport \u00e0 XY bien s\u00fbr. Donc ce risque fonctionnel, c'est l'esp\u00e9rance, donc selon la distribution de probabilit\u00e9s jointes P du XY, de notre fonction de coup L. \u00c7a, \u00e7a repr\u00e9sente en moyenne le co\u00fbt pour toutes les donn\u00e9es possibles. Et donc c'est l\u00e0 que \u00e7a devient compliqu\u00e9, parce qu'on n'a pas toutes les donn\u00e9es. Il est impossible d'avoir toutes les donn\u00e9es possibles. Par contre, ce qu'on a, c'est notre ensemble d'apprentissages C. C'est notre \u00e9chantillon, et donc sur cet ensemble d'\u00e9chantillons C, on peut bien s\u00fbr calculer et mesurer le risque empirique, qui est donc la moyenne pour l'ensemble des donn\u00e9es d'apprentissage de ce que donne la fonction de coup sur ces donn\u00e9es d'apprentissage. Et ce qu'on cherche \u00e0 faire, c'est minimiser le risque. Donc est-ce qu'on peut se contenter de minimiser, de chercher F, parmi une classe d'hypoth\u00e8ses, parmi un ensemble de fonctions F ? Ce qu'on va chercher \u00e0 faire, c'est trouver la fonction F qui va minimiser le risque. Donc comme on n'a que le risque empirique, est-ce qu'on peut se contenter finalement de chercher la fonction F, parmi notre classe d'hypoth\u00e8ses, qui va minimiser le risque empirique ? La r\u00e9ponse \u00e0 cette question, c'est non. Pourquoi ? Parce qu'en fait le risque empirique, il ne va pas permettre d'\u00e9valuer la pertinence du mod\u00e8le, parce que typiquement on peut tomber dans des probl\u00e8mes qu'on appelle des probl\u00e8mes de surapprentissage. C'est-\u00e0-dire qu'on va pouvoir, en minimisant le risque empirique, choisir une fonction F telle que le risque empirique va \u00eatre tr\u00e8s bas, voire nul. Et notamment, plus on prend une fonction F qui va \u00eatre complexe et qui va du coup fiter les donn\u00e9es, plus on va \u00eatre dans ce cas-l\u00e0. Mais par contre, sur de nouvelles donn\u00e9es, donc sur un ensemble de tests, ce risque, l'erreur de g\u00e9n\u00e9ralisation, elle va \u00eatre tr\u00e8s \u00e9lev\u00e9e. L'erreur de pr\u00e9diction, elle va \u00eatre \u00e9lev\u00e9e. Donc \u00e7a, c'est typiquement un cas tr\u00e8s connu en apprentissage, qui s'appelle le cas du surapprentissage. Donc la solution, en fait, \u00e7a va \u00eatre de minimiser le risque empirique, donc \u00e0 partir de notre \u00e9chantillon d'apprentissage, et on va rajouter \u00e0 ce risque empirique, en fait, un terme qu'on va appeler un terme de r\u00e9gularisation, qui va donc permettre la g\u00e9n\u00e9ralisation du mod\u00e8le d'apprentissage. Donc \u00e7a, c'est vraiment ce qu'a montr\u00e9 la th\u00e9orie de Vapnik, que la construction d'une fonction d'apprentissage, on peut la formaliser comme un probl\u00e8me de minimisation. Donc parmi une famille de fonctions qu'on appelle les classes d'hypoth\u00e8ses, chercher F appartenant \u00e0 F, qui va minimiser le risque empirique r\u00e9gularis\u00e9, donc avec un facteur de r\u00e9gularisation lambda. Voil\u00e0, donc, rapide bilan sur l'apprentissage supervis\u00e9. Un algorithme d'apprentissage a un ensemble de fonctions F, donc \u00e7a, c'est notre classe d'hypoth\u00e8ses. Par exemple, vous pouvez prendre l'ensemble des fonctions lin\u00e9aires, l'ensemble des fonctions de type r\u00e9seau de neurones, enfin voil\u00e0, on a ce qu'on appelle une classe d'hypoth\u00e8ses. Et ce que fait cet algorithme d'apprentissage, c'est qu'il va s\u00e9lectionner parmi cet ensemble de fonctions, la fonction la plus appropri\u00e9e, donc en utilisant l'ensemble d'apprentissage, donc la minimisation du risque empirique, et la fonction objective, donc notre fonction de co\u00fbt, avec bien s\u00fbr ajout\u00e9 \u00e0 ce risque empirique une fonction de r\u00e9gularisation qui, elle, est d\u00e9finie par l'utilisateur. Ensuite, cet algorithme d'apprentissage, il va r\u00e9aliser la s\u00e9lection de F, donc avec des m\u00e9thodes qui lui sont propres, qui sont souvent des techniques qui font appel \u00e0 des techniques d'optimisation, type des centres de gradients, par exemple, pour les r\u00e9seaux de neurones, passage au lagrangien pour les SVM, etc. Voil\u00e0, et un aspect important, en fait, de l'apprentissage dont je n'ai pas parl\u00e9, c'est la repr\u00e9sentation des exemples, c'est ce qu'on va donner en entr\u00e9e, finalement, de notre syst\u00e8me d'apprentissage. Donc \u00e7a, c'est typiquement une probl\u00e9matique qu'on appelle la probl\u00e9matique du feature engineering et qu'on oppose aujourd'hui aux approches qu'on appelle de repr\u00e9sentation learning, o\u00f9, en fait, on va apprendre aussi une repr\u00e9sentation de nos exemples, et c'est typiquement ce que permet de faire des approches de type apprentissage profond. Mais \u00e7a, c'est hors sujet, en fait, de type apprentissage profond. Mais \u00e7a, c'est hors sujet pour ce cours, aujourd'hui, en tout cas. Voil\u00e0, donc maintenant, on va revenir \u00e0 notre probl\u00e8me de recherche d'informations et on va s'int\u00e9resser plus sp\u00e9cifiquement \u00e0 des probl\u00e8mes de cat\u00e9gorisation et le lien avec la recherche d'informations. Donc, on va prendre comme exemple le probl\u00e8me de la cat\u00e9gorisation de documents. Donc, on peut tr\u00e8s facilement illustrer sous la forme de ce sch\u00e9ma-l\u00e0. Donc, on a nos deux phases classiques dans les syst\u00e8mes d'apprentissage, une phase d'entra\u00eenement du mod\u00e8le et une phase de pr\u00e9diction. Voil\u00e0, donc on a une collection de documents qui est labellis\u00e9e, \u00e9tiquet\u00e9e. Donc, pour chaque document, on a un ensemble d'\u00e9tiquettes. Les documents, donc, il y a toutes les tables de construction de feature engineering. Donc, typiquement, les documents, on va les repr\u00e9senter sous la forme de documents vectoris\u00e9s. Donc, par exemple, avec des repr\u00e9sentations TFIDF dans l'espace des termes du vocabulaire qu'on a construit sur la collection. Et puis, comme on a donc nos donn\u00e9es labellis\u00e9es, comme on a des \u00e9tiquettes, on va donc apprendre un mod\u00e8le de cat\u00e9gorisation sur ces donn\u00e9es-l\u00e0. Et puis, maintenant, on peut utiliser ce mod\u00e8le dans une phase de pr\u00e9diction pour un nouveau document test que je d\u00e9cris de la m\u00eame mani\u00e8re, bien s\u00fbr. Donc, je construis aussi une repr\u00e9sentation vectoris\u00e9e de mon document. J'utilise mon classifieur et je pr\u00e9dis donc une \u00e9tiquette pour des primes. Alors, si je d\u00e9finis \u00e7a de mani\u00e8re un peu plus formelle, je vais consid\u00e9rer un espace de repr\u00e9sentation pour mes documents quantiques. J'ai un ensemble de classes fix\u00e9es C, qui sont les diff\u00e9rentes cat\u00e9gories possibles pour mon document, donc l'ensemble des classes qui sont les classes d'\u00e9tiquettes. Et puis, j'ai donc mon ensemble d'apprentissages D qui est compos\u00e9 de paires D et C, les \u00e9tiquettes associ\u00e9es. Et puis, il va suffire d'apprendre une fonction F, un classifieur qui va associer les documents \u00e0 sa classe ou \u00e0 leur classe. Alors, \u00e7a peut \u00eatre un probl\u00e8me de classification multiclasse. Voil\u00e0. Alors, juste faites attention parce que ici j'ai chang\u00e9 mes notations et notamment C ici est mon ensemble de classes et non plus mon ensemble d'apprentissages et D n'est plus ma distribution de probabilit\u00e9s inconnues, mais c'est mon ensemble d'apprentissages. Je suis d\u00e9sol\u00e9e pour ce petit changement, donc j'insiste bien l\u00e0-dessus. Attention aux changements de notation par rapport aux slides pr\u00e9c\u00e9dentes. Voil\u00e0. Alors, il y a plein d'applications, en fait, de la cat\u00e9gorisation de documents pour la recherche d'informations. Il y a \u00e9norm\u00e9ment d'applications possibles. Par exemple, on a vu que toutes les techniques d'indexation \u00e9taient d\u00e9pendantes de la langue, ne serait-ce que l'\u00e9tape de tokenisation, m\u00eame si aujourd'hui il existe des tokenizers qui sont langages ind\u00e9pendants. Et du coup, il est souvent n\u00e9cessaire, \u00e9tant donn\u00e9 un document, d'identifier sa langue pour justement appliquer la bonne cha\u00eene de traitement linguistique. Eh bien, \u00e7a c'est un probl\u00e8me de cat\u00e9gorisation. L'ensemble des classes, c'est l'ensemble des langages du corpus, et puis ce qu'il faut, c'est \u00e9tant donn\u00e9 un document, pr\u00e9dire la langue du document. On peut aussi utiliser ce principe de cat\u00e9gorisation, par exemple dans le cas du web, pour d\u00e9tecter des pages qui sont des spams ou des pages qui sont des non-spams, et notamment pour \u00e9viter d'avoir \u00e0 indexer des pages qui sont des pages de type spam. Voil\u00e0, alors d'autres applications assez connues, c'est par exemple tout ce qui est d\u00e9tection de sentiments dans des donn\u00e9es qui sont des donn\u00e9es de r\u00e9seaux sociaux, voil\u00e0, type tweet, etc. Voil\u00e0, alors en recherche d'informations, une application aussi assez classique de la cat\u00e9gorisation de documents, c'est la d\u00e9tection de th\u00e9matiques ou la recherche de verticaux. Typiquement, dans les moteurs de recherche grand public, ce qu'on appelle un vertical ou les verticaux, c'est typiquement par exemple de limiter une recherche par exemple \u00e0 l'ensemble des actualit\u00e9s, ou \u00e0 l'ensemble des images, ou \u00e0 l'ensemble des vid\u00e9os. \u00c7a c'est des verticaux. Et donc, associer un document au type de vertical recherch\u00e9, ou quel il correspond, \u00e7a c'est un probl\u00e8me de classification. Voil\u00e0, alors on va du coup maintenant s'int\u00e9resser \u00e0 quelques algorithmes de cat\u00e9gorisation qui sont un peu les algorithmes historiques qu'on utilise pour la recherche d'informations. Voil\u00e0, il y a deux grandes familles d'algorithmes de cat\u00e9gorisation selon le type finalement de mod\u00e8les qu'on utilise. Il y a notamment des algorithmes qui sont des algorithmes qui font partie des mod\u00e8les qu'on appelle les mod\u00e8les g\u00e9n\u00e9ratifs. \u00c7a c'est typiquement les premiers mod\u00e8les d'apprentissage qui ont \u00e9t\u00e9 d\u00e9velopp\u00e9s pour la cat\u00e9gorisation de documents. Ces mod\u00e8les g\u00e9n\u00e9ratifs, en fait, ils se basent sur l'hypoth\u00e8se qui est \u00e9crite sur cette slide, qui consiste \u00e0 dire que chaque vecteur repr\u00e9sentatif d'un document D, on va le mod\u00e9liser comme la r\u00e9alisation d'une variable al\u00e9atoire multidimensionnelle, qui est g\u00e9n\u00e9r\u00e9e par le m\u00e9lange de cas densit\u00e9 de probabilit\u00e9 avec des proportions pica telles que la somme des pica pour l'ensemble des cas densit\u00e9 est \u00e9gale \u00e0 1. Et puis bien s\u00fbr pica c'est sup\u00e9rieur \u00e0 0. Donc typiquement, k c'est typiquement les diff\u00e9rentes classes possibles. Un exemple d'algorithme ou de m\u00e9thode de cat\u00e9gorisation qui fait partie de ces mod\u00e8les g\u00e9n\u00e9ratifs, c'est par exemple le classif\u00e8re Bayesien qui utilise du coup la r\u00e8gle de Bayes, le classif\u00e8re qu'on appelle le classif\u00e8re Bayesien na\u00eff. On peut aussi proposer des approches pour la cat\u00e9gorisation en utilisant des mod\u00e8les qu'on appelle les mod\u00e8les discriminants, qui eux vont directement trouver une fonction de classification F donc de grand Rd, qui est l'espace de repr\u00e9sentation de nos documents, dans grand Y et qui va r\u00e9soudre le probl\u00e8me de cat\u00e9gorisation sans faire d'hypoth\u00e8ses sur la mani\u00e8re dont sont g\u00e9n\u00e9r\u00e9s les exemples. Donc une fa\u00e7on un peu d'illustrer la diff\u00e9rence entre ces deux cat\u00e9gories de mod\u00e8les. Ici le mod\u00e8le g\u00e9n\u00e9ratif c'est vraiment le mod\u00e8le du peintre qui va typiquement essayer de reproduire au mieux le processus de g\u00e9n\u00e9ration de donn\u00e9es et ici c'est l'approche du caricaturiste qui va grossi\u00e8rement tracer les traits discriminants des donn\u00e9es. Alors un exemple d'approche de classification qui fait partie des mod\u00e8les discriminants c'est par exemple les SVM qui sont les s\u00e9parateurs \u00e0 vaste marge ou d'autres approches comme les capes le proche voisin ou le perceptron, des approches de r\u00e9gression logistique etc. Ce sont des mod\u00e8les discriminants. On va s'int\u00e9resser dans un premier temps \u00e0 des mod\u00e8les g\u00e9n\u00e9ratifs donc assez classiques en recherche d'informations. Notamment on va s'int\u00e9resser au classifieur Bayesian. Pour vous introduire ce classifieur Bayesian, je vais utiliser un exemple qui vient d'un tr\u00e8s bon cours d'apprentissage de Gilles Gassot o\u00f9 on prend un probl\u00e8me de classification jouet qui consiste \u00e0 classer un fruit comme en deux classes possibles comme poire donc \u00e7a c'est la classe C1 ou p\u00eache c'est la classe C2. Alors on peut classer un fruit donn\u00e9 qui est donc une donn\u00e9e d'entr\u00e9e en utilisant une probabilit\u00e9 a priori qui refl\u00e8terait notre connaissance qu'un fruit soit une poire ou une p\u00eache sans qu'on ait observ\u00e9 le dit fruit. Par exemple voil\u00e0 je regarde mon contexte je sais que nous sommes au mois de mai et donc voil\u00e0 ma connaissance me dit que la probabilit\u00e9 que le fruit soit une p\u00eache elle est plus forte que le fruit soit une poire selon l'aspect saisonnalit\u00e9. Donc on a bien s\u00fbr ces propri\u00e9t\u00e9s sur les probabilit\u00e9s a priori la probabilit\u00e9 a priori d'\u00eatre une poire plus la probabilit\u00e9 a priori d'\u00eatre une p\u00eache elle est \u00e9gale \u00e0 1 et puis du coup je peux utiliser ces probabilit\u00e9s a priori pour mon probl\u00e8me de classification. Typiquement je vais affecter le fruit \u00e0 la classe 1 si la probabilit\u00e9 a priori d'\u00eatre de la classe 1 donc d'\u00eatre une poire elle est plus grande que la probabilit\u00e9 a priori d'\u00eatre de la classe C donc d'\u00eatre une p\u00eache. On voit qu'en faisant \u00e7a donc sans prendre en compte les caract\u00e9ristiques intrins\u00e8ques des donn\u00e9es je risque d'avoir un risque d'erreur qui va \u00eatre important. Et donc pour contrabalancer \u00e7a l'id\u00e9e \u00e7a va \u00eatre de prendre en compte les caract\u00e9ristiques intrins\u00e8ques des donn\u00e9es de notre fruit et donc de passer par cette \u00e9tape de repr\u00e9sentation. De d\u00e9finir un ensemble de caract\u00e9ristiques X qui vont appartenir \u00e0 RDR et qui vont repr\u00e9senter le fruit comme par exemple sa forme sa couleur son odeur etc. Des choses qui vont caract\u00e9riser un ensemble d'observations sur l'objet qu'on cherche \u00e0 classifier. Et puis du coup je vais d\u00e9finir des lois conditionnelles pour les diff\u00e9rentes classes. Donc mes deux classes C1 poire C2 p\u00eache donc P de X sachant C1 et P de X sachant C2. Typiquement une illustration possible de ces lois conditionnelles avec en rouge la classe C1 et en bleu la classe C2. Du coup je vais en utilisant le th\u00e9or\u00e8me de Bayes pouvoir calculer la probabilit\u00e9 a posteriori de ces cas sachant X. Cette probabilit\u00e9 a posteriori je l'obtiens avec le th\u00e9or\u00e8me de Bayes et il m'est fourni par cette \u00e9quation. P de X sachant C4 fois la probabilit\u00e9 a priori de ces cas sur la somme entre P de X sachant C1 probabilit\u00e9 a priori de C1 plus P de X sachant C2 plus la probabilit\u00e9 a priori de C2. \u00c7a c'est le th\u00e9or\u00e8me de Bayes. Et en utilisant du coup ces probabilit\u00e9s a posteriori je vais avoir une nouvelle r\u00e8gle de d\u00e9cision qui va consister \u00e0 affecter X \u00e0 la classe de plus forte probabilit\u00e9 a posteriori. Donc si la probabilit\u00e9 a posteriori de poire sachant X est plus grande \u00e0 la probabilit\u00e9 a posteriori de p\u00eache sachant X alors X est de la classe poire c'est une instance de poire. Donc je d\u00e9finis ainsi avec cette r\u00e8gle de d\u00e9cision une fronti\u00e8re de d\u00e9cision. On va l'appeler une fronti\u00e8re de d\u00e9cision. Puis typiquement je vais pouvoir qualifier cette fronti\u00e8re de d\u00e9cision justement en regardant comment \u00e7a se comporte sur sur des donn\u00e9es de test. Typiquement en regardant le taux d'erreur c'est \u00e0 dire le nombre de mod\u00e8les de mauvaise d\u00e9cision sur le nombre total de d\u00e9cisions. Voil\u00e0 donc la d\u00e9marche qu'on va mettre en oeuvre pour des mod\u00e8les g\u00e9n\u00e9ratifs de type classif eurb\u00e9gien. C'est celle que je vais pr\u00e9senter juste maintenant. J'observe un ensemble de caract\u00e9ristiques not\u00e9es X qui d\u00e9crivent une entit\u00e9. Je suppose qu'une entit\u00e9 provient d'une classe donn\u00e9e et je vais prendre une d\u00e9cision en fonction de l'observation de ces caract\u00e9ristiques. Chaque d\u00e9cision, action, va donc avoir un certain co\u00fbt en fonction de la classe \u00e0 laquelle appartient X. Et puis l'objectif du classif eurb\u00e9gien \u00e7a va \u00eatre de trouver une r\u00e8gle de d\u00e9cision qui va minimiser un co\u00fbt moyen d\u00e9finissant quelles d\u00e9cisions prendre en fonction de l'entit\u00e9 observ\u00e9e. On retrouve ici les objectifs de notre apprentissage au supervis\u00e9. Quelques notations qui vont \u00eatre utiles pour la suite. On a un ensemble de classes C1, C4, de probabilit\u00e9 a priori PR de CK, c'est \u00e0 dire la probabilit\u00e9 que C est \u00e9gale \u00e0 CK pour chaque classe. On a donc un espace de caract\u00e9ristiques X. Typiquement X peut \u00eatre \u00e9gal \u00e0 Rd. Et puis on a donc la probabilit\u00e9 \u00e0... a posteriori, la probabilit\u00e9 que C est \u00e9gale \u00e0 CK, sachant que X est \u00e9gale \u00e0 X. On va noter P de CK sachant X. La loi conditionnelle de X \u00e0 la classe CK, c'est la probabilit\u00e9 de X sachant CK, c'est \u00e9gal \u00e0 la probabilit\u00e9 que la variable al\u00e9atoire X prenne la valeur X, sachant que la classe C est \u00e9gale \u00e0 CK. La loi marginale de X, on va la d\u00e9finir sur l'ensemble des classes possibles. C'est la somme pour l'ensemble des classes possibles de la loi conditionnelle de X \u00e0 la classe CK fois la probabilit\u00e9 a priori de CK. Le probl\u00e8me, \u00e7a va \u00eatre trouver la classe de X par une approche probabiliste en utilisant le maximum a posteriori. La classe pour X, \u00e7a va \u00eatre la classe qui va permettre de maximiser cette quantit\u00e9-l\u00e0. La remax selon K de cette quantit\u00e9-l\u00e0. Ce qu'il va falloir faire pour mettre en \u0153uvre le classifiant ab\u00e9zien, \u00e7a va \u00eatre d'estimer les quantit\u00e9s de cette formule \u00e0 partir de notre ensemble d'observation, donc \u00e0 partir de notre ensemble d'apprentissage. Typiquement, ce qu'on va chercher \u00e0 estimer, c'est les probabilit\u00e9s PR de CK, donc la probabilit\u00e9 a priori pour chaque classe, et la probabilit\u00e9, la loi conditionnelle de X \u00e0 la classe CK, donc P de X sachant CK. On a maintenant tout ce qu'il faut pour appliquer ces mod\u00e8les g\u00e9n\u00e9ratifs \u00e0 notre probl\u00e8me de cat\u00e9gorisation de documents. Je reviens sur l'hypoth\u00e8se dont j'ai d\u00e9j\u00e0 parl\u00e9, qui va consister \u00e0 consid\u00e9rer que chaque vecteur repr\u00e9sentatif d'un document D, c'est la r\u00e9alisation d'une variable al\u00e9atoire multidimensionnelle, qui va \u00eatre g\u00e9n\u00e9r\u00e9e par le m\u00e9lange de K densit\u00e9 de probabilit\u00e9, avec des proportions \u03c0K. K \u00e9tant le nombre de classes possibles. Avec ces propri\u00e9t\u00e9s-l\u00e0, la somme des \u03c0K pour l'ensemble des classes possibles, c'est 1, et \u03c0K, c'est sup\u00e9rieur ou \u00e9gal \u00e0 0. Chaque fonction de densit\u00e9, c'est une fonction param\u00e9trique qui mod\u00e9lise la distribution de probabilit\u00e9 conditionnelle de classe, associ\u00e9e \u00e0 une classe K qui appartient \u00e0 Y. Cette distribution de probabilit\u00e9 conditionnelle de classe, on va l'exprimer comme une fonction de densit\u00e9, donc une fonction param\u00e9trique avec des param\u00e8tres \u03b8K. Pour la classe K. La densit\u00e9 de m\u00e9lange, elle mod\u00e9lise quoi ? Elle mod\u00e9lise finalement la g\u00e9n\u00e9ration de D par ses K densit\u00e9 de probabilit\u00e9. Le mod\u00e8le g\u00e9n\u00e9ratif de D \u00e9tant donn\u00e9 l'ensemble des param\u00e8tres, c'est une loi de m\u00e9lange, c'est la somme pour l'ensemble des classes possibles, de \u03c0K fois cette fonction de densit\u00e9 associ\u00e9e \u00e0 chaque classe. Exactement comme tout \u00e0 l'heure, la poire ou la p\u00eache finalement. Ici, les classes sont diff\u00e9rentes. Donc, Theta, c'est l'ensemble des proportions \u03c0K et tous les param\u00e8tres qui d\u00e9finissent les fonctions de densit\u00e9 fK. Donc, \u03b8, c'est l'ensemble des \u03c0K pour chacune des classes possibles et puis les param\u00e8tres des lois de densit\u00e9. Le but de l'apprentissage, \u00e7a va \u00eatre d'estimer cet ensemble de param\u00e8tres \u03b8 pour qu'au sens du maximum de vraisemblance, le mod\u00e8le de m\u00e9lange explique au mieux les exemples de la base d'entra\u00eenement. Apr\u00e8s cette estimation des param\u00e8tres, on va pouvoir classer un nouveau document des primes \u00e0 une classe de l'ensemble Y en utilisant la r\u00e8gle de d\u00e9cision Bayesian que j'ai pr\u00e9sent\u00e9e tout \u00e0 l'heure. Des primes va appartenir \u00e0 la classe classe, 6K, c'est la remax pour l'ensemble des classes possibles, de P, de Y et de H, sachant des primes. Avec Bayes, toute cette \u00e9quation, je peux l'\u00e9crire comme \u00e7a, en faisant intervenir les param\u00e8tres de ma loi de m\u00e9lange, les param\u00e8tres de mon mod\u00e8le g\u00e9n\u00e9ratif. La vraie question, c'est comment estimer ces param\u00e8tres. Il y a deux mod\u00e8les qui vont faire des hypoth\u00e8ses sur notre repr\u00e9sentation du document qui vont nous permettre d'arriver \u00e0 une estimation possible de ces param\u00e8tres et donc \u00e0 des mod\u00e8les g\u00e9n\u00e9ratifs de cat\u00e9gorisation effectifs pour la cat\u00e9gorisation de documents. Un de ces premiers mod\u00e8les, c'est le mod\u00e8le multivari\u00e9 de Bernoulli qui va consid\u00e9rer que les documents sont ind\u00e9pendants et le mod\u00e8le multinomial. Commen\u00e7ons par le mod\u00e8le multivari\u00e9 de Bernoulli. Ce mod\u00e8le, ce n'est rien d'autre qu'une g\u00e9n\u00e9ralisation du mod\u00e8le probabiliste MIB que Myriam vous avait pr\u00e9sent\u00e9 lors du cours sur les mod\u00e8les probabilistes. L'hypoth\u00e8se de ce mod\u00e8le multivari\u00e9 de Bernoulli, c'est l'hypoth\u00e8se Na\u00efve Bayes qui dit que les termes qui apparaissent dans un document sont ind\u00e9pendants les uns des autres. Chaque document, on va le repr\u00e9senter comme un vecteur binaire d\u00e9fini sur l'espace des termes d'indexation, l'espace des termes de notre vocabulaire, construit sur notre collection, avec WID qui vaut 0 ou 1, selon que le terme est pr\u00e9sent ou non dans notre document. Si j'introduis cette repr\u00e9sentation vectorielle de D dans mes lois de densit\u00e9, F de k de D, \u03b8 k, va \u00eatre \u00e9gal \u00e0 la probabilit\u00e9 pour D qui est \u00e9gale \u00e0 sa repr\u00e9sentation sachant Y est \u00e9gale \u00e0 k. Comme j'ai fait l'hypoth\u00e8se que les termes \u00e9taient ind\u00e9pendants les uns des autres, \u00e7a va \u00eatre \u00e9gal au produit pour l'ensemble des termes de la probabilit\u00e9 de WID sachant que Y est \u00e9gale \u00e0 k. Si je pose quelques notations, et notamment je vais consid\u00e9rer que \u03b8 de TI sachant k, c'est la probabilit\u00e9 que le terme i soit pr\u00e9sent dans le document D, donc WID est \u00e9gal \u00e0 1 sachant Y est \u00e9gal \u00e0 k, c'est typiquement la probabilit\u00e9 de pr\u00e9sence du terme TI du vocabulaire dans la classe K, alors ma loi de densit\u00e9, je peux pour D, associer donc \u00e0 D pour la classe K, avec les param\u00e8tres \u03b8 k, je vais pouvoir l'\u00e9crire de cette mani\u00e8re. Donc c'est le produit pour chacun des termes de cette quantit\u00e9 l\u00e0. Voil\u00e0, \u00e7a c'est ce qu'on appelle une loi de Bernoulli. Alors pourquoi \u00e7a s'appelle une loi de Bernoulli ? Parce que les \u00e9v\u00e9nements qui mod\u00e9lisent l'absence ou la pr\u00e9sence de termes du vocabulaire dans les diff\u00e9rentes classes, elles suivent ce qu'on appelle une loi de Bernoulli dont les param\u00e8tres sont propres \u00e0 chaque terme. Voil\u00e0, donc ici \u03b8 k, \u00e7a repr\u00e9sente l'ensemble des probabilit\u00e9s de pr\u00e9sence des termes du vocabulaire dans la KM classe ou dans la KM composante du m\u00e9lange. Et puis ce qu'on va chercher \u00e0 estimer, c'est ce grand \u03b8, donc cet ensemble de param\u00e8tres \u03b8 de k, c'est-\u00e0-dire pour chaque classe K, \u03c0k, et puis \u03b8 de ti sachant k. Cette estimation, on va pouvoir la faire au sens du maximum de vraisemblance des param\u00e8tres sur une base d'apprentissage C de taille M. Et en particulier, pour l'ensemble des termes de notre vocabulaire et pour l'ensemble des classes, \u03b8 de ti sachant k, on va pouvoir l'estimer comme \u00e9tant cette quantit\u00e9-l\u00e0, c'est-\u00e0-dire le df pour le terme i de la classe K sur nk de C. Et puis \u03c0k, on va pouvoir l'estimer comme \u00e9tant n de K sur C sur M. Alors, \u00e0 quoi correspondent ces diff\u00e9rentes quantit\u00e9s ? n de K de C, c'est \u00e9gal au cardinal de SK, donc le cardinal de la classe SK, c'est l'ensemble des documents de la base d'apprentissage qui appartiennent \u00e0 la classe K. M, c'est le nombre total de documents dans notre base d'apprentissage. Et df de T de K, c'est le nombre de documents de la classe K qui contiennent au moins une fois le terme T. Donc \u00e7a, c'est l'estimation des param\u00e8tres de notre mod\u00e8le multivari\u00e9 de Bernoulli au sens du maximum de vraisemblance. En pratique, on ajoute \u00e0 ces estimations un lissage de la place et un passage au logarithme pour la r\u00e8gle de Bayes. Je vous ai mis sur les deux slides qui suivent les algorithmes qui correspondent \u00e0 la phase d'apprentissage et \u00e0 la phase de test, mais je vous laisserai regarder ces algorithmes \u00e0 t\u00eate repos\u00e9e. Je ne vais pas les d\u00e9tailler dans cette vid\u00e9o. Je vais acc\u00e9l\u00e9rer un peu. L'autre mod\u00e8le g\u00e9n\u00e9ratif qui est tr\u00e8s utilis\u00e9 en cat\u00e9gorisation pour la RI, c'est le mod\u00e8le multinomial, dans lequel on va consid\u00e9rer qu'un document D est repr\u00e9sent\u00e9 comme une s\u00e9quence ordonn\u00e9e de termes D. L'ordre des termes est pris en compte. La repr\u00e9sentation d'un document D, c'est une s\u00e9quence ordonn\u00e9e. Et cette s\u00e9quence ordonn\u00e9e est g\u00e9n\u00e9r\u00e9e \u00e0 partir d'un vocabulaire V donn\u00e9. On a toujours l'hypoth\u00e8se Na\u00efve-Bayes qui dit cette fois-ci que la probabilit\u00e9 de g\u00e9n\u00e9ration d'un terme par une composante du m\u00e9lange, par une classe, est ind\u00e9pendante du contexte et de la position de ce terme dans le document. Comme pour le mod\u00e8le de Bernoulli, on va inclure cette repr\u00e9sentation D sous la forme d'une s\u00e9quence ordonn\u00e9e de termes dans notre loi de densit\u00e9. En utilisant l'hypoth\u00e8se de Bayes, cette loi de densit\u00e9 associ\u00e9e \u00e0 la classe K, va \u00eatre \u00e9gale au produit pour l'ensemble des termes qui appartiennent \u00e0 un document de \u03b8 de TH, avec le \u03b8 de TH, qui est la probabilit\u00e9 de g\u00e9n\u00e9ration du terme TH par la Km composante du m\u00e9lange, par la Km classe. Ce qu'introduit ce mod\u00e8le multinomial par rapport au mod\u00e8le de Bernoulli, au mod\u00e8le pr\u00e9c\u00e9dent, c'est qu'il va capturer l'information de fr\u00e9quence des termes dans les documents, et plus seulement l'information de pr\u00e9sence-absence. On a vu plusieurs fois, notamment quand on a introduit le mod\u00e8le vectorial, que prendre en compte cette fr\u00e9quence des termes, \u00e7a avait un int\u00e9r\u00eat et \u00e7a a un impact sur les r\u00e9sultats. Comme pour le mod\u00e8le pr\u00e9c\u00e9dent, il faut estimer les param\u00e8tres. Il y a une erreur d'ailleurs ici, c'est le mod\u00e8le multinomial, je suis d\u00e9sol\u00e9e, je viens de m'en rendre compte. On estime ces param\u00e8tres au sens du maximum de vraisemblance sur une base d'apprentissage C de taille M, en introduisant un lissage de la place. Au sens du maximum de vraisemblance, on peut estimer les diff\u00e9rents param\u00e8tres de notre mod\u00e8le g\u00e9n\u00e9ratif, de cette mani\u00e8re-l\u00e0, o\u00f9 on voit qu'on a pris en compte la fr\u00e9quence des termes dans les documents. On a toujours ici un NK2C1 qui est le cardinal de la classe K dans notre ensemble d'apprentissage, et puis ici un TF2TID, c'est le nombre d'occurrences du terme TI dans le document D. S2K, c'est l'ensemble des documents de notre ensemble d'apprentissage qui appartiennent \u00e0 la classe K. Voil\u00e0, donc \u00e0 nouveau, je vous ai mis le d\u00e9tail des algorithmes pour la phase d'apprentissage et pour la phase de test, mais que je ne d\u00e9taillerai pas ici. On peut bien s\u00fbr aussi utiliser des mod\u00e8les discriminants, qui eux vont consister \u00e0 directement trouver une fonction F de classification, sans faire finalement d'hypoth\u00e8se sur la mani\u00e8re dont sont g\u00e9n\u00e9r\u00e9s les exemples. L\u00e0, on va retomber sur des choses que j'ai introduites tout \u00e0 l'heure sur l'apprentissage supervis\u00e9. Le classifieur recherch\u00e9 est suppos\u00e9 appartenir \u00e0 une classe de fonctions donn\u00e9es F, donc ma classe d'hypoth\u00e8se, et la forme analytique de cette fonction F, je vais la trouver en minimisant une fonction d'erreur, notre fonction de co\u00fbt d\u00e9finie tout \u00e0 l'heure. Tr\u00e8s souvent, comme on est dans un probl\u00e8me de classification, ici on utilise le co\u00fbt 0,1, o\u00f9 je vais compter le nombre de fausses pr\u00e9dictions, je vais p\u00e9naliser le nombre de fausses pr\u00e9dictions de ma fonction F. Un mod\u00e8le discriminant tr\u00e8s connu, ce sont les s\u00e9parateurs \u00e0 vaste marge lin\u00e9aire. L'objectif, c'est \u00e9tant donn\u00e9 nos donn\u00e9es d'apprentissage, qui sont \u00e9tiquet\u00e9es de mani\u00e8re binaire selon deux classes, moins 1 ou plus 1, on va chercher \u00e0 construire \u00e0 partir de cet ensemble d'apprentissage, une fonction F de d\u00e9cision qui va permettre de pr\u00e9dire la classe moins 1 ou plus 1 d'un point quelconque X appartenant \u00e0 notre ensemble d'entr\u00e9es grand X. La fonction de d\u00e9cision, je veux que ce soit une fonction de d\u00e9cision lin\u00e9aire. Voil\u00e0, donc \u00e7a c'est la forme analytique de cette fonction de d\u00e9cision lin\u00e9aire. Et puis l'apprentissage, \u00e7a va consister \u00e0 apprendre les param\u00e8tres W, J et B de cette fonction F, tel que je vais minimiser mon risque empirique. Je ne vais pas plus rentrer dans les d\u00e9tails de ces SVM, parce que je d\u00e9taillerai \u00e7a un peu plus pr\u00e9cis\u00e9ment lors de la prochaine s\u00e9ance. On va maintenant passer au dernier gros morceau du cours d'aujourd'hui, qui concerne l'apprentissage pour la RIE et l'ordonnancement. L'id\u00e9e, \u00e7a va \u00eatre de mod\u00e9liser la recherche d'informations comme un probl\u00e8me de cat\u00e9gorisation, pour se ramener \u00e0 un probl\u00e8me d'apprentissage. L'id\u00e9e g\u00e9n\u00e9rale, \u00e7a va \u00eatre de choisir une repr\u00e9sentation des exemples. Encore faut-il dire quels sont les exemples qu'on va consid\u00e9rer dans ce cadre-l\u00e0. Il va aussi falloir dire \u00e0 quoi correspondent les classes de sortie et quels sont leurs nombres. Une fois qu'on a un peu d\u00e9fini ces donn\u00e9es d'entr\u00e9e, il faut choisir le principe d'apprentissage et l'algorithme associ\u00e9. Ou faire en sorte d'en tester plusieurs et de choisir celui qui est le plus optimal. Revenons \u00e0 notre probl\u00e9matique de recherche d'informations. J'ai des requ\u00eates, et je vais consid\u00e9rer que j'ai des requ\u00eates pour lesquelles je dispose de jugements de pertinence dans ces. Typiquement, j'ai une requ\u00eate Q1 et un ensemble de documents avec leurs jugements de pertinence. En bleu, c'est les documents pertinents, en orange, c'est les documents non pertinents pour la requ\u00eate Q1. Et puis j'ai la m\u00eame chose pour une requ\u00eate Q2 et j'ai la m\u00eame chose pour une requ\u00eate Q3. Ces requ\u00eates pour lesquelles je dispose de jugements de pertinence, c'est \u00e7a qui va nous permettre de d\u00e9finir un ensemble d'apprentissages que je vais utiliser pour ensuite apprendre une fonction F, qui va \u00eatre utilis\u00e9e apr\u00e8s pour faire de la recherche d'informations. Les principaux verrous de l'apprentissage par ordonnancement, c'est de d\u00e9terminer quelles sont les donn\u00e9es qu'on va utiliser pour mettre en place l'apprentissage. La probl\u00e9matique de la notation des donn\u00e9es d'apprentissage, typiquement on voit bien qu'une sortie c'est mes jugements de pertinence, et donc quel jugement de pertinence je vais prendre en compte. Comment je d\u00e9cris mes donn\u00e9es ? \u00c0 partir du moment o\u00f9 j'ai d\u00e9fini mes donn\u00e9es, qui sont des couples requ\u00eates documents, comment je les d\u00e9cris, donc quelles sont les caract\u00e9ristiques que je vais utiliser pour d\u00e9crire mes donn\u00e9es. Et puis bien s\u00fbr, apr\u00e8s, quel mod\u00e8le d'apprentissage j'utilise, quelle fonction de coup, quel algorithme, etc. Et puis apr\u00e8s, se pose aussi la question de comment j'\u00e9value cette fonction F que j'ai apprise \u00e0 partir des donn\u00e9es. Quelles sont les mesures que je vais pouvoir utiliser pour mon \u00e9valuation ? La premi\u00e8re question, la question de comment je repr\u00e9sente mes donn\u00e9es, elle est fondamentale. C'est un probl\u00e8me crucial, qui est l'\u00e9tape qu'on appelle l'\u00e9tape de Feature Engineering. On a vu que les donn\u00e9es que je dois consid\u00e9rer pour faire de l'ordonnancement, ce ne sont pas les documents seuls, mais \u00e7a va \u00eatre des couples documents requ\u00eates. Et donc \u00e0 ce couple documents requ\u00eates, je vais pouvoir utiliser les donn\u00e9es que je vais utiliser pour faire de l'ordonnancement. Pour ce couple documents requ\u00eates, je vais devoir associer une repr\u00e9sentation standard X qui va \u00eatre d\u00e9finie dans RM, avec un M dimension. Les coordonn\u00e9es de X, je vais vouloir qu'elles soient tr\u00e8s g\u00e9n\u00e9rales. On va essayer de se reposer sur un maximum d'informations, et notamment, pourquoi pas, r\u00e9utiliser tout ce qu'on a introduit jusqu'\u00e0 maintenant dans le cours. Par exemple, je peux prendre comme premi\u00e8re dimension de mon vecteur X, la somme pour l'ensemble des termes qui appartiennent \u00e0 la fois au document et \u00e0 la requ\u00eate, du log de la fr\u00e9quence du terme dans le document. Comme deuxi\u00e8me composante, je peux par exemple prendre cette quantit\u00e9 l\u00e0, qui est pour l'ensemble des termes de la requ\u00eate, le log de 1 plus la fr\u00e9quence du terme dans le document sur le nombre de documents dans ma collection. Et puis voil\u00e0, je peux comme \u00e7a construire une repr\u00e9sentation X en prenant du coup un ensemble de mesures statistiques, de statistiques que je peux construire \u00e0 partir de ma requ\u00eate et de mon document. Je peux aussi par exemple prendre les scores qui me sont donn\u00e9s par d'autres mod\u00e8les, comme par exemple le mod\u00e8le vectoriel, le mod\u00e8le bool\u00e9en, le mod\u00e8le probabiliste, etc. L\u00e0, il n'y a rien qui est interdit il faut juste que j'associe \u00e0 ce couple QD un vecteur qui le caract\u00e9rise au mieux dans cette probl\u00e9matique de recherche d'informations. Voil\u00e0, donc \u00e7a c'est l'\u00e9tape fondamentale qui est l'\u00e9tape de Feature Engineering. Et donc \u00e0 une requ\u00eate et \u00e0 un ensemble de documents, donc je vais construire ce vecteur de caract\u00e9ristiques avec des choses, un ensemble de caract\u00e9ristiques qui sont d\u00e9pendantes du couple requ\u00eate-documents, mais aussi \u00e9ventuellement des caract\u00e9ristiques qui sont purement d\u00e9pendantes du document, par exemple on peut mettre le page rank, voire des caract\u00e9ristiques qui peuvent \u00eatre purement d\u00e9pendantes de la requ\u00eate, etc. Voil\u00e0, l'autre probl\u00e8me c'est finalement les valeurs de sortie, donc le choix du nombre de classes. Ce choix du nombre de classes, il d\u00e9pend a priori des valeurs de pertinence qu'on a \u00e0 notre disposition. Est-ce que j'ai des valeurs de pertinence binaires, est-ce que j'ai des valeurs de pertinence multivalu\u00e9es ou des scores de pertinence ? Donc \u00e7a, on voit bien qu'il est assez facile d'avoir des valeurs de pertinence binaires. Si je veux des valeurs de pertinence multivalu\u00e9es ou des scores de pertinence, \u00e7a peut n\u00e9cessiter un travail d'annotation de longue haleine. Et puis bien s\u00fbr, c'est aussi tr\u00e8s d\u00e9pendant du syst\u00e8me en question et des pr\u00e9f\u00e9rences des concepteurs. Voil\u00e0, dans le cas le plus simple, j'ai deux classes, la classe des documents pertinents et la classe des documents non pertinents, et du coup je peux me ramener tr\u00e8s facilement \u00e0 un probl\u00e8me de cat\u00e9gorisation binaire. Voil\u00e0, alors j'ai d'autres possibilit\u00e9s. Si je dispose d'annotations du rang, donc avec des jugements binaires, donc documents pertinents ou non pertinents, je me ram\u00e8ne \u00e0 un probl\u00e8me de cat\u00e9gorisation binaire. Si j'ai des jugements multivalu\u00e9s, donc avec par exemple ce type de jugement, parfait, excellent, bon, meilleur, etc., des \u00e9chelles de graduation, je peux me ramener \u00e0 un probl\u00e8me de cat\u00e9gorisation multiclasse. Je peux aussi vouloir annoter des paires ordonn\u00e9es, et notamment, je peux avoir des paires de pr\u00e9f\u00e9rence. Donc typiquement, et \u00e7a c'est des choses qui sont assez faciles \u00e0 avoir dans le cadre du web, ces paires de pr\u00e9f\u00e9rence, en utilisant par exemple l'analyse des clics. Donc j'ai plut\u00f4t \u00e0 voir comme donn\u00e9e de sortie, en fait, le fait qu'un document D va \u00eatre plus pertinent qu'un autre document pour une requ\u00eate de donn\u00e9es. Voil\u00e0, donc \u00e7a c'est des choses qu'on peut tr\u00e8s facilement obtenir \u00e0 partir des informations de clics, \u00e0 partir du comportement utilisateur. Et puis, je peux avoir aussi des listes, avec donc des annotations de listes qui sont meilleures pour une requ\u00eate qu'une autre liste de documents. \u00c7a c'est des choses qui sont un peu plus difficiles \u00e0 mettre en \u0153uvre. Voil\u00e0, donc le choix du nombre de classes, vos valeurs de sortie, elles sont bien s\u00fbr tr\u00e8s d\u00e9pendantes du type d'annotation que vous pouvez associer \u00e0 vos donn\u00e9es, et notamment \u00e0 ces couples documents requ\u00eates. Voil\u00e0, alors apr\u00e8s la question du choix du principe d'apprentissage et de l'algorithme, typiquement elle est plus compliqu\u00e9e \u00e0 partir du moment o\u00f9 on a trait\u00e9 les deux pr\u00e9c\u00e9dentes questions. Donc apr\u00e8s la repr\u00e9sentation des donn\u00e9es, en fait, toutes les techniques de cat\u00e9gorisation peuvent \u00e0 priori \u00eatre utilis\u00e9es. Elles seront plus ou moins efficaces, mais elles peuvent \u00e0 priori toutes \u00eatre utilis\u00e9es. Voil\u00e0, donc on utilise beaucoup, ou on a beaucoup utilis\u00e9 les SVM parce qu'il y a une application assez directe. Typiquement, chaque couple QD contenant un document pertinent pour Q, elle va \u00eatre associ\u00e9e \u00e0 la classe plus 1, et les exemples avec les documents non pertinents \u00e0 la classe moins 1. On va donc apprendre un hyperplan s\u00e9parateur \u00e0 partir de cet ensemble d'apprentissage. Voil\u00e0, donc je vais chercher les param\u00e8tres avec la th\u00e9orie des SVM. Et puis, la valeur de sortie, elle me donnera directement une mesure pour d\u00e9finir un ordre sur les documents. Voil\u00e0, et donc le score d'un nouveau document pour une nouvelle requ\u00eate, il va \u00eatre directement fond\u00e9 sur les valeurs des fonctions de cat\u00e9gorisation associ\u00e9es. Voil\u00e0, alors apr\u00e8s, il y a trois grandes familles d'approches d'apprentissage pour l'ordonnancement. La premi\u00e8re famille d'approches, c'est l'approche qu'on appelle l'approche par points. En fait, les documents vont \u00eatre trait\u00e9s de mani\u00e8re ind\u00e9pendante dans cette approche. On ne va pas prendre en compte des pertes de pertinence, comme je l'ai expliqu\u00e9 tout \u00e0 l'heure. On va avoir donc des approches par paire, o\u00f9 l\u00e0 on va prendre en compte des pertes de pertinence, c'est l'approche perouaise, et on peut aussi avoir des approches par liste. Je vais me contenter pour la fin de ce cours de parler de l'approche par points et je reviendrai sur les approches par paire et par liste lors du prochain cours. Le principe de l'approche par points, c'est ce qu'on vient de voir, c'est-\u00e0-dire qu'on va formaliser le probl\u00e8me d'ordonnancement comme un probl\u00e8me de cat\u00e9gorisation ou de r\u00e9gression. Les documents, je les consid\u00e8re de mani\u00e8re ind\u00e9pendante en entr\u00e9e du syst\u00e8me d'apprentissage. Et puis, mon jugement de pertinence, \u00e7a peut \u00eatre soit un score r\u00e9el, auquel cas je vais me rapporter un probl\u00e8me de r\u00e9gression lin\u00e9aire, soit une classe de pertinence ordonn\u00e9e, auquel cas je peux me rapporter un probl\u00e8me de r\u00e9gression ordinal, soit j'ai une classe de pertinence non ordonn\u00e9e, et l\u00e0 je peux utiliser des techniques de classification. L'approche par points, on appelle \u00e7a une approche par points parce que mes documents sont consid\u00e9r\u00e9s de mani\u00e8re ind\u00e9pendante en entr\u00e9e du syst\u00e8me d'apprentissage. Si j'ai un score de pertinence r\u00e9el, je me ram\u00e8ne \u00e0 un probl\u00e8me de r\u00e9gression lin\u00e9aire et je vais r\u00e9soudre ce probl\u00e8me de r\u00e9gression en minimisant pour chaque document une fonction de perte, qui est par exemple la somme des diff\u00e9rences au carr\u00e9. Avec Y qui est le score de pertinence de r\u00e9f\u00e9rence pour un document DI et Y qui est le score de pertinence pr\u00e9dit. La fonction de perte, c'est la diff\u00e9rence au carr\u00e9, et puis du coup, mon risque empirique, \u00e7a va \u00eatre la somme des diff\u00e9rences au carr\u00e9. Si j'ai des classes de pertinence ordonn\u00e9e, et puis si j'ai des classes de pertinence ordonn\u00e9e, je vais avoir un probl\u00e8me de r\u00e9gression ordinale, qui va prendre en compte l'ordre relatif entre les classes, et du coup il va s'agir de d\u00e9terminer F qui est une fonction d'ordonnancement qui va retourner un score r\u00e9el de pertinence et N moins un seuil qui d\u00e9termine la r\u00e9gression ordinaire. Et puis, si j'ai des classes de pertinence ordonn\u00e9e, qui va retourner un score r\u00e9el de pertinence et N moins un seuil qui d\u00e9terminent finalement les limites des N cat\u00e9gories de pertinence. Voil\u00e0, concernant ce premier cours sur l'apprentissage pour l'ARI. En conclusion, ce que je vous ai pr\u00e9sent\u00e9 aujourd'hui, il y a une grosse partie qui \u00e9tait quand m\u00eame une partie de rappel sur l'apprentissage, mais sinon je vous ai pr\u00e9sent\u00e9 un nouveau paradigme pour l'ARI. J'ai d\u00e9taill\u00e9 \u00e0 la fin de ce cours l'approche par points, o\u00f9 le probl\u00e8me d'ordonnancement, on le transforme en un probl\u00e8me de cat\u00e9gorisation ou de r\u00e9gression. Ces approches d'apprentissage, il faut retenir que ce sont des approches qui vont tenter d'exploiter toutes les informations \u00e0 disposition. On a des r\u00e9sultats qui vont \u00eatre comparables \u00e0 ceux des mod\u00e8les probabilistes quand on a des collections qui sont classiques. Quand on a des grosses collections, et notamment par exemple dans le cas du web, pour lequel on peut disposer d'un espace d'attributs qui est tr\u00e8s riche, on va avoir des meilleurs r\u00e9sultats. Apr\u00e8s, il peut se poser des probl\u00e8mes de mal\u00e9diction de la dimension, et typiquement si notre description de notre couple requ\u00eate document est tr\u00e8s grand, on peut avoir apr\u00e8s des probl\u00e8mes de mal\u00e9diction de la dimension. On peut se poser des questions de r\u00e9duction de cette dimension pour \u00e9viter ces probl\u00e8mes. Il y a un probl\u00e8me qui est non n\u00e9gligeable, qui est la disponibilit\u00e9 des annotations. Comment je peux obtenir des jugements de pertinence, pour constituer un jeu de donn\u00e9es d'apprentissage, pour apr\u00e8s mettre en oeuvre toutes ces techniques d'apprentissage ? Voil\u00e0 quelques petites lectures conseill\u00e9es pour compl\u00e9ter cette premi\u00e8re partie du cours. Je vous souhaite de bien mettre tout cela en application lors du Lab d'aujourd'hui."
}